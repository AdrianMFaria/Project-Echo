{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Imports\n",
    "##################################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "# import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import plot_model\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #ignore warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'aflw2k3d',\n",
       " 'amazon_us_reviews',\n",
       " 'bair_robot_pushing_small',\n",
       " 'bigearthnet',\n",
       " 'binarized_mnist',\n",
       " 'binary_alpha_digits',\n",
       " 'caltech101',\n",
       " 'caltech_birds2010',\n",
       " 'caltech_birds2011',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'chexpert',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar10_corrupted',\n",
       " 'clevr',\n",
       " 'cnn_dailymail',\n",
       " 'coco',\n",
       " 'coco2014',\n",
       " 'coil100',\n",
       " 'colorectal_histology',\n",
       " 'colorectal_histology_large',\n",
       " 'curated_breast_imaging_ddsm',\n",
       " 'cycle_gan',\n",
       " 'deep_weeds',\n",
       " 'definite_pronoun_resolution',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'downsampled_imagenet',\n",
       " 'dsprites',\n",
       " 'dtd',\n",
       " 'dummy_dataset_shared_generator',\n",
       " 'dummy_mnist',\n",
       " 'emnist',\n",
       " 'eurosat',\n",
       " 'fashion_mnist',\n",
       " 'flores',\n",
       " 'food101',\n",
       " 'gap',\n",
       " 'glue',\n",
       " 'groove',\n",
       " 'higgs',\n",
       " 'horses_or_humans',\n",
       " 'image_label_folder',\n",
       " 'imagenet2012',\n",
       " 'imagenet2012_corrupted',\n",
       " 'imdb_reviews',\n",
       " 'iris',\n",
       " 'kitti',\n",
       " 'kmnist',\n",
       " 'lfw',\n",
       " 'lm1b',\n",
       " 'lsun',\n",
       " 'mnist',\n",
       " 'mnist_corrupted',\n",
       " 'moving_mnist',\n",
       " 'multi_nli',\n",
       " 'nsynth',\n",
       " 'omniglot',\n",
       " 'open_images_v4',\n",
       " 'oxford_flowers102',\n",
       " 'oxford_iiit_pet',\n",
       " 'para_crawl',\n",
       " 'patch_camelyon',\n",
       " 'pet_finder',\n",
       " 'quickdraw_bitmap',\n",
       " 'resisc45',\n",
       " 'rock_paper_scissors',\n",
       " 'rock_you',\n",
       " 'scene_parse150',\n",
       " 'shapes3d',\n",
       " 'smallnorb',\n",
       " 'snli',\n",
       " 'so2sat',\n",
       " 'squad',\n",
       " 'stanford_dogs',\n",
       " 'stanford_online_products',\n",
       " 'starcraft_video',\n",
       " 'sun397',\n",
       " 'super_glue',\n",
       " 'svhn_cropped',\n",
       " 'ted_hrlr_translate',\n",
       " 'ted_multi_translate',\n",
       " 'tf_flowers',\n",
       " 'titanic',\n",
       " 'trivia_qa',\n",
       " 'uc_merced',\n",
       " 'ucf101',\n",
       " 'visual_domain_decathlon',\n",
       " 'voc2007',\n",
       " 'wikipedia',\n",
       " 'wmt14_translate',\n",
       " 'wmt15_translate',\n",
       " 'wmt16_translate',\n",
       " 'wmt17_translate',\n",
       " 'wmt18_translate',\n",
       " 'wmt19_translate',\n",
       " 'wmt_t2t_translate',\n",
       " 'wmt_translate',\n",
       " 'xnli']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show tfds datasets\n",
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\regin\\Documents\\SIT374\\Project-Echo\\src\\Prototypes\\engine\\AddCAMtoMelSpec\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'kagglecatsanddogs_5340\\\\PetImages\\\\Cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m cat_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkagglecatsanddogs_5340\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPetImages\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m dog_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkagglecatsanddogs_5340\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPetImages\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDog\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCat images:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_dir\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m10\u001b[39m])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#make cat dataset\u001b[39;00m\n\u001b[0;32m     13\u001b[0m cat_img \u001b[38;5;241m=\u001b[39m image_dataset_from_directory(\n\u001b[0;32m     14\u001b[0m     cat_dir,\n\u001b[0;32m     15\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     16\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'kagglecatsanddogs_5340\\\\PetImages\\\\Cat'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "#show directory location\n",
    "print(os.getcwd())\n",
    "#load cats_vs_dogs dataset\n",
    "cat_dir = 'kagglecatsanddogs_5340\\PetImages\\Cat'\n",
    "dog_dir = 'kagglecatsanddogs_5340\\PetImages\\Dog'\n",
    "\n",
    "print(\"Cat images:\", os.listdir(cat_dir)[:10])\n",
    "#make cat dataset\n",
    "cat_img = image_dataset_from_directory(\n",
    "    cat_dir,\n",
    "    batch_size=32,\n",
    "    labels = None)\n",
    "\n",
    "print(\"Dog images:\", os.listdir(dog_dir)[:10])\n",
    "#make dog dataset\n",
    "dog_img = image_dataset_from_directory(\n",
    "    dog_dir,\n",
    "    batch_size=32,\n",
    "    labels = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the first 5 images\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show(image):\n",
    "  plt.figure()\n",
    "  plt.imshow(image)\n",
    "  plt.axis('off')\n",
    "\n",
    "for image in cat_img.take(5):\n",
    "  show(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Activation Map\n",
    "class activation mapping (CAM)  utilize the responses of a convolutional layer for explanations. CAM linearly combine activation maps to produce visual explanation maps.\n",
    "CAM can improve the interpretability of neural networks, by investigating the weights of the area in the image that influence the model's prediction. \n",
    "\n",
    "Let's have a short demo on this function using cats vs dogs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset cats_vs_dogs (786.68 MiB) to C:\\Users\\regin\\tensorflow_datasets\\cats_vs_dogs\\2.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e0fb64f39f4898b02b11c7a0bdeea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cf3b4ef86c4717ad74f601bb94bc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "DownloadError",
     "evalue": "Failed to get url https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip. HTTP code: 404.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDownloadError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m TEST_DS_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#get the first 2000 data as training data\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m cat_dog_train \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcats_vs_dogs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain[:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mTRAIN_DS_SIZE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mwith_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_supervised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#get data 2001 to 3000 as validation data\u001b[39;00m\n\u001b[0;32m      9\u001b[0m cat_dog_valid \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcats_vs_dogs\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTRAIN_DS_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTRAIN_DS_SIZE\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mVALID_DS_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m,with_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, as_supervised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py:52\u001b[0m, in \u001b[0;36mdisallow_positional_args.<locals>.disallow_positional_args_dec\u001b[1;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m _check_no_positional(fn, args, ismethod, allowed\u001b[38;5;241m=\u001b[39mallowed)\n\u001b[0;32m     51\u001b[0m _check_required(fn, kwargs)\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py:300\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, in_memory, shuffle_files, download, as_supervised, decoders, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m    299\u001b[0m   download_and_prepare_kwargs \u001b[38;5;241m=\u001b[39m download_and_prepare_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m--> 300\u001b[0m   dbuilder\u001b[38;5;241m.\u001b[39mdownload_and_prepare(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdownload_and_prepare_kwargs)\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_dataset_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m   as_dataset_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py:52\u001b[0m, in \u001b[0;36mdisallow_positional_args.<locals>.disallow_positional_args_dec\u001b[1;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m _check_no_positional(fn, args, ismethod, allowed\u001b[38;5;241m=\u001b[39mallowed)\n\u001b[0;32m     51\u001b[0m _check_required(fn, kwargs)\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:285\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, download_dir, download_config)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_format_adapter\u001b[38;5;241m.\u001b[39mincomplete_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_dir) \u001b[38;5;28;01mas\u001b[39;00m tmp_data_dir:\n\u001b[0;32m    282\u001b[0m   \u001b[38;5;66;03m# Temporarily assign _data_dir to tmp_data_dir to avoid having to forward\u001b[39;00m\n\u001b[0;32m    283\u001b[0m   \u001b[38;5;66;03m# it to every sub function.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mtemporary_assignment(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_data_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m, tmp_data_dir):\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# NOTE: If modifying the lines below to put additional information in\u001b[39;00m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;66;03m# DatasetInfo, you'll likely also want to update\u001b[39;00m\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;66;03m# DatasetInfo.read_from_directory to possibly restore these attributes\u001b[39;00m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;66;03m# when reading from package data.\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# Update the DatasetInfo metadata by computing statistics from the data.\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (download_config\u001b[38;5;241m.\u001b[39mcompute_stats \u001b[38;5;241m==\u001b[39m download\u001b[38;5;241m.\u001b[39mComputeStatsMode\u001b[38;5;241m.\u001b[39mSKIP \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    296\u001b[0m         download_config\u001b[38;5;241m.\u001b[39mcompute_stats \u001b[38;5;241m==\u001b[39m download\u001b[38;5;241m.\u001b[39mComputeStatsMode\u001b[38;5;241m.\u001b[39mAUTO \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mtotal_num_examples)\n\u001b[0;32m    298\u001b[0m        ):\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:946\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, download_config):\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# Extract max_examples_per_split and forward it to _prepare_split\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGeneratorBasedBuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_examples_per_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_examples_per_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:804\u001b[0m, in \u001b[0;36mFileAdapterBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Generating data for all splits\u001b[39;00m\n\u001b[0;32m    803\u001b[0m split_dict \u001b[38;5;241m=\u001b[39m splits_lib\u001b[38;5;241m.\u001b[39mSplitDict()\n\u001b[1;32m--> 804\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split_generator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    805\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m splits_lib\u001b[38;5;241m.\u001b[39mSplit\u001b[38;5;241m.\u001b[39mALL \u001b[38;5;241m==\u001b[39m split_generator\u001b[38;5;241m.\u001b[39msplit_info\u001b[38;5;241m.\u001b[39mname:\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    807\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtfds.Split.ALL is a special split keyword corresponding to the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munion of all splits, so cannot be used as key in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m._split_generator().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\tensorflow_datasets\\image\\cats_vs_dogs.py:81\u001b[0m, in \u001b[0;36mCatsVsDogs._split_generators\u001b[1;34m(self, dl_manager)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_split_generators\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager):\n\u001b[1;32m---> 81\u001b[0m   path \u001b[38;5;241m=\u001b[39m \u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_URL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m   \u001b[38;5;66;03m# There is no predefined train/val/test split for this dataset.\u001b[39;00m\n\u001b[0;32m     84\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     85\u001b[0m       tfds\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mSplitGenerator(\n\u001b[0;32m     86\u001b[0m           name\u001b[38;5;241m=\u001b[39mtfds\u001b[38;5;241m.\u001b[39mSplit\u001b[38;5;241m.\u001b[39mTRAIN,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m           }),\n\u001b[0;32m     91\u001b[0m   ]\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:301\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;66;03m# Add progress bar to follow the download state\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_downloader\u001b[38;5;241m.\u001b[39mtqdm():\n\u001b[1;32m--> 301\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_promise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:395\u001b[0m, in \u001b[0;36m_map_promise\u001b[1;34m(map_fn, all_inputs)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[39;00m\n\u001b[0;32m    394\u001b[0m all_promises \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mmap_nested(map_fn, all_inputs)  \u001b[38;5;66;03m# Apply the function\u001b[39;00m\n\u001b[1;32m--> 395\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_wait_on_promise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_promises\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py:143\u001b[0m, in \u001b[0;36mmap_nested\u001b[1;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[0;32m    141\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(mapped)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Singleton\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:379\u001b[0m, in \u001b[0;36m_wait_on_promise\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait_on_promise\u001b[39m(p):\n\u001b[1;32m--> 379\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\promise\\promise.py:512\u001b[0m, in \u001b[0;36mPromise.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    510\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target()\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait(timeout \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_TIMEOUT)\n\u001b[1;32m--> 512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_target_settled_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_raise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\promise\\promise.py:516\u001b[0m, in \u001b[0;36mPromise._target_settled_value\u001b[1;34m(self, _raise)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_target_settled_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, _raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;66;03m# type: (bool) -> Any\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settled_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_raise\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\promise\\promise.py:226\u001b[0m, in \u001b[0;36mPromise._settled_value\u001b[1;34m(self, _raise)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _raise:\n\u001b[0;32m    225\u001b[0m     raise_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fulfillment_handler0\n\u001b[1;32m--> 226\u001b[0m     \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraise_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_traceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fulfillment_handler0\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\six.py:719\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    721\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\promise\\promise.py:844\u001b[0m, in \u001b[0;36m_process_future_result.<locals>.handle_future_result\u001b[1;34m(future)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_future_result\u001b[39m(future):\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;66;03m# type: (Any) -> None\u001b[39;00m\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 844\u001b[0m         resolve(\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    846\u001b[0m         tb \u001b[38;5;241m=\u001b[39m exc_info()[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\regin\\.conda\\envs\\project_echo\\lib\\site-packages\\tensorflow_datasets\\core\\download\\downloader.py:233\u001b[0m, in \u001b[0;36m_Downloader._sync_download\u001b[1;34m(self, url, destination_path)\u001b[0m\n\u001b[0;32m    231\u001b[0m   response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mget(url, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    232\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m--> 233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DownloadError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to get url \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. HTTP code: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    234\u001b[0m                         (url, response\u001b[38;5;241m.\u001b[39mstatus_code))\n\u001b[0;32m    235\u001b[0m fname \u001b[38;5;241m=\u001b[39m _get_filename(response)\n\u001b[0;32m    236\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(destination_path, fname)\n",
      "\u001b[1;31mDownloadError\u001b[0m: Failed to get url https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip. HTTP code: 404."
     ]
    }
   ],
   "source": [
    "#load catvs dog data\n",
    "TRAIN_DS_SIZE = 2000\n",
    "VALID_DS_SIZE = 1000\n",
    "TEST_DS_SIZE = 1000\n",
    "\n",
    "#get the first 2000 data as training data\n",
    "cat_dog_train = tfds.load('cats_vs_dogs', split=f'train[:{TRAIN_DS_SIZE}]',with_info=True, as_supervised=True)\n",
    "#get data 2001 to 3000 as validation data\n",
    "cat_dog_valid = tfds.load('cats_vs_dogs', split=f'train[{TRAIN_DS_SIZE}:{TRAIN_DS_SIZE + VALID_DS_SIZE}]',with_info=True, as_supervised=True)\n",
    "#get data 3001 to 4000 as test data\n",
    "cat_dog_test = tfds.load('cats_vs_dogs', split=f'train[{TRAIN_DS_SIZE + VALID_DS_SIZE}:{TRAIN_DS_SIZE + VALID_DS_SIZE + TEST_DS_SIZE}]',with_info=True, as_supervised=True)\n",
    "\n",
    "#note: as supervides mean it will return the label with the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m##################################################\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Preprocessing\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m##################################################\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Imagenet mean/std\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m normalize \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241m.\u001b[39mNormalize(\n\u001b[0;32m      7\u001b[0m    mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m],\n\u001b[0;32m      8\u001b[0m    std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m]\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Scale to 224x224, convert to tensor, and normalize with mean/std for ImageNet\u001b[39;00m\n\u001b[0;32m     12\u001b[0m preprocess \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     13\u001b[0m    transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)),\n\u001b[0;32m     14\u001b[0m    transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m     15\u001b[0m    normalize,\n\u001b[0;32m     16\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
