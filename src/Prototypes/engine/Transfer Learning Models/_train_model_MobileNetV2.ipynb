{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"0AqYbtehvlUZ"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27068,"status":"ok","timestamp":1714550789236,"user":{"displayName":"TANMAY PACHPANDE","userId":"08132729217334205753"},"user_tz":-600},"id":"WvE0rM9uyfah","outputId":"609e96f0-bd7b-460d-b171-114eec38cc46"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Q-yUdZLWyPDD"},"outputs":[],"source":["import os\n","os.chdir(\n","    \"C:\\\\Users\\\\ptanmay143\\\\Data\\\\Projects\\\\project-echo/src/Prototypes/engine/Transfer Learning Models\"\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"9Oxyu9lnRnqD"},"outputs":[],"source":["from _model_config import *"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":97349,"status":"ok","timestamp":1714550890039,"user":{"displayName":"TANMAY PACHPANDE","userId":"08132729217334205753"},"user_tz":-600},"id":"_U2dr35UxpQe","outputId":"328866c3-c5f5-4c10-d87c-2a02ac4399a0"},"outputs":[],"source":["# %pip install diskcache -q\n","# %pip install audiomentations==0.29.0 -q\n","# %pip install tensorflow==2.10.0 -q\n","# %pip install keras==2.10.0 -q\n","# %pip install tensorflow_addons -q"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26313,"status":"ok","timestamp":1714550916340,"user":{"displayName":"TANMAY PACHPANDE","userId":"08132729217334205753"},"user_tz":-600},"id":"Q0r1crUevlUb","outputId":"f7e9a262-a274-4f2d-f9ba-638b30b4bfd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python Version           :  3.8.16\n","TensorFlow Version       :  2.10.1\n","Keras Version            :  2.10.0\n","Librosa Version          :  0.10.1\n","Audiomentations Version  :  0.35.0\n","Found 7514 files belonging to 118 classes.\n","Class names:  ['Acanthiza chrysorrhoa', 'Acanthiza lineata', 'Acanthiza nana', 'Acanthiza pusilla', 'Acanthiza reguloides', 'Acanthiza uropygialis', 'Acanthorhynchus tenuirostris', 'Accipiter cirrocephalus', 'Aidemosyne modesta', 'Alauda arvensis', 'Anhinga novaehollandiae', 'Anthochaera phrygia', 'Antigone rubicunda', 'Artamus cinereus', 'Artamus cyanopterus', 'Artamus minor', 'Artamus superciliosus', 'Barnardius zonarius', 'Callocephalon fimbriatum', 'Calyptorhynchus banksii', 'Calyptorhynchus lathami', 'Capra Hircus', 'Carduelis carduelis', 'Carterornis leucotis', 'Cervus Unicolour', 'Ceyx azureus', 'Chenonetta jubata', 'Chlamydera nuchalis', 'Cincloramphus mathewsi', 'Cinclosoma punctatum', 'Cisticola exilis', 'Climacteris picumnus', 'Colluricincla harmonica', 'Conopophila albogularis', 'Cophixalus exiguus', 'Cophixalus infacetus', 'Cophixalus ornatus', 'Coracina novaehollandiae', 'Coracina papuensis', 'Corcorax melanorhamphos', 'Cormobates leucophaea', 'Corvus mellori', 'Coturnix pectoralis', 'Cygnus atratus', 'Dama Dama', 'Daphoenositta chrysoptera', 'Dasyurus maculatus', 'Dicaeum hirundinaceum', 'Egretta novaehollandiae', 'Elseyornis melanops', 'Entomyzon cyanotis', 'Eurostopodus argus', 'Eurostopodus mystacalis', 'Eurystomus orientalis', 'Falco berigora', 'Falco cenchroides', 'Falco peregrinus', 'Falcunculus frontatus', 'Felis Catus', 'Fulica atra', 'Gallinula tenebrosa', 'Geopelia cuneata', 'Gerygone mouki', 'Haliastur sphenurus', 'Irediparra gallinacea', 'Lalage leucomela', 'Litoria inermis', 'Manorina melanophrys', 'Megapodius reinwardt', 'Melithreptus brevirostris', 'Melithreptus gularis', 'Melithreptus lunatus', 'Microeca flavigaster', 'Neophema pulchella', 'Nesoptilotis leucotis', 'Pachycephala simplex', 'Pardalotus rubricatus', 'Parvipsitta pusilla', 'Pelecanus conspicillatus', 'Petrochelidon ariel', 'Petrochelidon nigricans', 'Petroica boodang', 'Petroica goodenovii', 'Petroica phoenicea', 'Petroica rosea', 'Pezoporus wallicus', 'Phaps elegans', 'Philemon citreogularis', 'Philemon corniculatus', 'Phylidonyris niger', 'Pitta iris', 'Pitta versicolor', 'Platycercus elegans', 'Plectorhyncha lanceolata', 'Psophodes cristatus', 'Ptilinopus regina', 'Pycnoptilus floccosus', 'Ramsayornis fasciatus', 'Ranoidea caerulea', 'Rattus Norvegicus', 'Rhinella marina', 'Rhipidura albiscapa', 'Rhipidura leucophrys', 'Rhipidura rufifrons', 'Rhipidura rufiventris', 'Scythrops novaehollandiae', 'Spilopelia chinensis', 'Stizoptera bichenovii', 'Stomiopera unicolor', 'Strepera versicolor', 'Sus Scrofa', 'Symposiachrus trivirgatus', 'Tregellasia capito', 'Trichosurus vulpecula', 'Uperoleia altissima', 'Uperoleia mimula', 'Vanellus miles', 'Vulpes vulpes']\n","Training dataset length: 6011\n","Validation dataset length: 1427\n","Test dataset length: 76\n"]}],"source":["exec(f\"from {MODEL_NAME} import *\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"INkqi6buvlUd","outputId":"0788c476-1ce7-4a56-fb78-0d72766ab04d"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","____________________________________________________________________________\n"," Layer (type)                Output Shape              Param #   Trainable  \n","============================================================================\n"," input_2 (InputLayer)        [(None, 299, 299, 3)]     0         Y          \n","                                                                            \n"," mobilenetv2_1.00_224 (Funct  (None, 10, 10, 1280)     2257984   N          \n"," ional)                                                                     \n","                                                                            \n"," global_average_pooling2d (G  (None, 1280)             0         Y          \n"," lobalAveragePooling2D)                                                     \n","                                                                            \n"," dropout (Dropout)           (None, 1280)              0         Y          \n","                                                                            \n"," dense (Dense)               (None, 118)               151158    Y          \n","                                                                            \n","============================================================================\n","Total params: 2,409,142\n","Trainable params: 151,158\n","Non-trainable params: 2,257,984\n","____________________________________________________________________________\n","Epoch 1/5000\n","376/376 [==============================] - 640s 2s/step - loss: 4.0783 - accuracy: 0.0983 - val_loss: 3.8038 - val_accuracy: 0.1808 - lr: 1.0000e-04\n","Epoch 2/5000\n","376/376 [==============================] - 571s 2s/step - loss: 3.7887 - accuracy: 0.1592 - val_loss: 3.5916 - val_accuracy: 0.2207 - lr: 1.0000e-04\n","Epoch 3/5000\n","376/376 [==============================] - 425s 1s/step - loss: 3.6073 - accuracy: 0.1875 - val_loss: 3.4160 - val_accuracy: 0.2509 - lr: 1.0000e-04\n","Epoch 4/5000\n","376/376 [==============================] - 368s 978ms/step - loss: 3.4805 - accuracy: 0.2088 - val_loss: 3.2863 - val_accuracy: 0.2698 - lr: 1.0000e-04\n","Epoch 5/5000\n","376/376 [==============================] - 335s 889ms/step - loss: 3.3474 - accuracy: 0.2337 - val_loss: 3.1631 - val_accuracy: 0.2845 - lr: 1.0000e-04\n","Epoch 6/5000\n","376/376 [==============================] - 317s 841ms/step - loss: 3.2422 - accuracy: 0.2429 - val_loss: 3.0611 - val_accuracy: 0.3048 - lr: 1.0000e-04\n","Epoch 7/5000\n","376/376 [==============================] - 301s 797ms/step - loss: 3.1432 - accuracy: 0.2619 - val_loss: 2.9692 - val_accuracy: 0.3280 - lr: 1.0000e-04\n","Epoch 8/5000\n","376/376 [==============================] - 296s 788ms/step - loss: 3.0690 - accuracy: 0.2836 - val_loss: 2.8982 - val_accuracy: 0.3385 - lr: 1.0000e-04\n","Epoch 9/5000\n","376/376 [==============================] - 282s 748ms/step - loss: 2.9822 - accuracy: 0.3013 - val_loss: 2.8225 - val_accuracy: 0.3581 - lr: 1.0000e-04\n","Epoch 10/5000\n","376/376 [==============================] - 286s 759ms/step - loss: 2.9346 - accuracy: 0.3071 - val_loss: 2.7633 - val_accuracy: 0.3700 - lr: 1.0000e-04\n","Epoch 11/5000\n","376/376 [==============================] - 268s 713ms/step - loss: 2.8549 - accuracy: 0.3219 - val_loss: 2.6972 - val_accuracy: 0.3889 - lr: 1.0000e-04\n","Epoch 12/5000\n","376/376 [==============================] - 247s 656ms/step - loss: 2.8059 - accuracy: 0.3362 - val_loss: 2.6473 - val_accuracy: 0.4114 - lr: 1.0000e-04\n","Epoch 13/5000\n","376/376 [==============================] - 242s 643ms/step - loss: 2.7434 - accuracy: 0.3490 - val_loss: 2.5999 - val_accuracy: 0.4128 - lr: 1.0000e-04\n","Epoch 14/5000\n","376/376 [==============================] - 226s 600ms/step - loss: 2.7096 - accuracy: 0.3499 - val_loss: 2.5604 - val_accuracy: 0.4170 - lr: 1.0000e-04\n","Epoch 15/5000\n","376/376 [==============================] - 228s 605ms/step - loss: 2.6576 - accuracy: 0.3627 - val_loss: 2.5158 - val_accuracy: 0.4317 - lr: 1.0000e-04\n","Epoch 16/5000\n","376/376 [==============================] - 221s 588ms/step - loss: 2.6192 - accuracy: 0.3750 - val_loss: 2.4765 - val_accuracy: 0.4303 - lr: 1.0000e-04\n","Epoch 17/5000\n","376/376 [==============================] - 209s 556ms/step - loss: 2.5708 - accuracy: 0.3845 - val_loss: 2.4407 - val_accuracy: 0.4373 - lr: 1.0000e-04\n","Epoch 18/5000\n","376/376 [==============================] - 206s 544ms/step - loss: 2.5334 - accuracy: 0.3949 - val_loss: 2.4057 - val_accuracy: 0.4506 - lr: 1.0000e-04\n","Epoch 19/5000\n","376/376 [==============================] - 197s 521ms/step - loss: 2.4993 - accuracy: 0.4034 - val_loss: 2.3711 - val_accuracy: 0.4562 - lr: 1.0000e-04\n","Epoch 20/5000\n","376/376 [==============================] - 191s 507ms/step - loss: 2.4663 - accuracy: 0.4041 - val_loss: 2.3408 - val_accuracy: 0.4709 - lr: 1.0000e-04\n","Epoch 21/5000\n","376/376 [==============================] - 183s 487ms/step - loss: 2.4242 - accuracy: 0.4204 - val_loss: 2.3233 - val_accuracy: 0.4597 - lr: 1.0000e-04\n","Epoch 22/5000\n","376/376 [==============================] - 177s 468ms/step - loss: 2.3987 - accuracy: 0.4277 - val_loss: 2.2990 - val_accuracy: 0.4660 - lr: 1.0000e-04\n","Epoch 23/5000\n","376/376 [==============================] - 168s 443ms/step - loss: 2.3775 - accuracy: 0.4234 - val_loss: 2.2680 - val_accuracy: 0.4856 - lr: 1.0000e-04\n","Epoch 24/5000\n","376/376 [==============================] - 156s 413ms/step - loss: 2.3569 - accuracy: 0.4364 - val_loss: 2.2430 - val_accuracy: 0.4870 - lr: 1.0000e-04\n","Epoch 25/5000\n","376/376 [==============================] - 141s 375ms/step - loss: 2.3168 - accuracy: 0.4493 - val_loss: 2.2165 - val_accuracy: 0.4891 - lr: 1.0000e-04\n","Epoch 26/5000\n","376/376 [==============================] - 142s 376ms/step - loss: 2.2987 - accuracy: 0.4455 - val_loss: 2.1976 - val_accuracy: 0.4968 - lr: 1.0000e-04\n","Epoch 27/5000\n","376/376 [==============================] - 137s 364ms/step - loss: 2.2775 - accuracy: 0.4488 - val_loss: 2.1821 - val_accuracy: 0.5004 - lr: 1.0000e-04\n","Epoch 28/5000\n","376/376 [==============================] - 138s 367ms/step - loss: 2.2549 - accuracy: 0.4510 - val_loss: 2.1676 - val_accuracy: 0.4996 - lr: 1.0000e-04\n","Epoch 29/5000\n","376/376 [==============================] - 132s 349ms/step - loss: 2.2499 - accuracy: 0.4613 - val_loss: 2.1423 - val_accuracy: 0.5088 - lr: 1.0000e-04\n","Epoch 30/5000\n","376/376 [==============================] - 149s 397ms/step - loss: 2.2175 - accuracy: 0.4578 - val_loss: 2.1310 - val_accuracy: 0.5165 - lr: 1.0000e-04\n","Epoch 31/5000\n","376/376 [==============================] - 144s 380ms/step - loss: 2.1859 - accuracy: 0.4740 - val_loss: 2.1084 - val_accuracy: 0.5172 - lr: 1.0000e-04\n","Epoch 32/5000\n","376/376 [==============================] - 138s 366ms/step - loss: 2.1797 - accuracy: 0.4671 - val_loss: 2.0998 - val_accuracy: 0.5137 - lr: 1.0000e-04\n","Epoch 33/5000\n","376/376 [==============================] - 140s 373ms/step - loss: 2.1568 - accuracy: 0.4746 - val_loss: 2.0850 - val_accuracy: 0.5193 - lr: 1.0000e-04\n","Epoch 34/5000\n","376/376 [==============================] - 134s 355ms/step - loss: 2.1408 - accuracy: 0.4783 - val_loss: 2.0637 - val_accuracy: 0.5151 - lr: 1.0000e-04\n","Epoch 35/5000\n","376/376 [==============================] - 136s 359ms/step - loss: 2.1229 - accuracy: 0.4796 - val_loss: 2.0567 - val_accuracy: 0.5214 - lr: 1.0000e-04\n","Epoch 36/5000\n","376/376 [==============================] - 130s 345ms/step - loss: 2.1104 - accuracy: 0.4881 - val_loss: 2.0427 - val_accuracy: 0.5256 - lr: 1.0000e-04\n","Epoch 37/5000\n","376/376 [==============================] - 116s 307ms/step - loss: 2.1021 - accuracy: 0.4833 - val_loss: 2.0287 - val_accuracy: 0.5319 - lr: 1.0000e-04\n","Epoch 38/5000\n","376/376 [==============================] - 107s 283ms/step - loss: 2.0721 - accuracy: 0.4946 - val_loss: 2.0163 - val_accuracy: 0.5361 - lr: 1.0000e-04\n","Epoch 39/5000\n","376/376 [==============================] - 111s 293ms/step - loss: 2.0693 - accuracy: 0.4966 - val_loss: 2.0098 - val_accuracy: 0.5298 - lr: 1.0000e-04\n","Epoch 40/5000\n","376/376 [==============================] - 100s 265ms/step - loss: 2.0345 - accuracy: 0.5031 - val_loss: 1.9976 - val_accuracy: 0.5389 - lr: 1.0000e-04\n","Epoch 41/5000\n","376/376 [==============================] - 105s 279ms/step - loss: 2.0303 - accuracy: 0.5011 - val_loss: 1.9857 - val_accuracy: 0.5396 - lr: 1.0000e-04\n","Epoch 42/5000\n","376/376 [==============================] - 100s 267ms/step - loss: 2.0028 - accuracy: 0.5056 - val_loss: 1.9761 - val_accuracy: 0.5424 - lr: 1.0000e-04\n","Epoch 43/5000\n","376/376 [==============================] - 106s 282ms/step - loss: 1.9988 - accuracy: 0.5069 - val_loss: 1.9629 - val_accuracy: 0.5410 - lr: 1.0000e-04\n","Epoch 44/5000\n","376/376 [==============================] - 110s 290ms/step - loss: 2.0019 - accuracy: 0.5149 - val_loss: 1.9520 - val_accuracy: 0.5424 - lr: 1.0000e-04\n","Epoch 45/5000\n","376/376 [==============================] - 108s 287ms/step - loss: 1.9914 - accuracy: 0.5081 - val_loss: 1.9473 - val_accuracy: 0.5508 - lr: 1.0000e-04\n","Epoch 46/5000\n","376/376 [==============================] - 101s 269ms/step - loss: 1.9758 - accuracy: 0.5096 - val_loss: 1.9343 - val_accuracy: 0.5571 - lr: 1.0000e-04\n","Epoch 47/5000\n","376/376 [==============================] - 99s 264ms/step - loss: 1.9568 - accuracy: 0.5232 - val_loss: 1.9287 - val_accuracy: 0.5529 - lr: 1.0000e-04\n","Epoch 48/5000\n","376/376 [==============================] - 100s 263ms/step - loss: 1.9266 - accuracy: 0.5195 - val_loss: 1.9239 - val_accuracy: 0.5543 - lr: 1.0000e-04\n","Epoch 49/5000\n","376/376 [==============================] - 102s 269ms/step - loss: 1.9536 - accuracy: 0.5190 - val_loss: 1.9147 - val_accuracy: 0.5480 - lr: 1.0000e-04\n","Epoch 50/5000\n","376/376 [==============================] - 94s 247ms/step - loss: 1.9446 - accuracy: 0.5142 - val_loss: 1.9012 - val_accuracy: 0.5578 - lr: 1.0000e-04\n","Epoch 51/5000\n","376/376 [==============================] - 81s 213ms/step - loss: 1.9120 - accuracy: 0.5280 - val_loss: 1.8908 - val_accuracy: 0.5585 - lr: 1.0000e-04\n","Epoch 52/5000\n","376/376 [==============================] - 83s 221ms/step - loss: 1.9090 - accuracy: 0.5290 - val_loss: 1.8891 - val_accuracy: 0.5599 - lr: 1.0000e-04\n","Epoch 53/5000\n","376/376 [==============================] - 70s 183ms/step - loss: 1.8990 - accuracy: 0.5352 - val_loss: 1.8882 - val_accuracy: 0.5634 - lr: 1.0000e-04\n","Epoch 54/5000\n","376/376 [==============================] - 70s 186ms/step - loss: 1.8959 - accuracy: 0.5378 - val_loss: 1.8678 - val_accuracy: 0.5669 - lr: 1.0000e-04\n","Epoch 55/5000\n","376/376 [==============================] - 68s 180ms/step - loss: 1.8754 - accuracy: 0.5370 - val_loss: 1.8655 - val_accuracy: 0.5641 - lr: 1.0000e-04\n","Epoch 56/5000\n","376/376 [==============================] - 66s 173ms/step - loss: 1.8684 - accuracy: 0.5405 - val_loss: 1.8531 - val_accuracy: 0.5704 - lr: 1.0000e-04\n","Epoch 57/5000\n","376/376 [==============================] - 63s 166ms/step - loss: 1.8606 - accuracy: 0.5350 - val_loss: 1.8453 - val_accuracy: 0.5788 - lr: 1.0000e-04\n","Epoch 58/5000\n","376/376 [==============================] - 65s 173ms/step - loss: 1.8404 - accuracy: 0.5398 - val_loss: 1.8434 - val_accuracy: 0.5711 - lr: 1.0000e-04\n","Epoch 59/5000\n","376/376 [==============================] - 62s 163ms/step - loss: 1.8418 - accuracy: 0.5437 - val_loss: 1.8336 - val_accuracy: 0.5669 - lr: 1.0000e-04\n","Epoch 60/5000\n","376/376 [==============================] - 68s 181ms/step - loss: 1.8450 - accuracy: 0.5382 - val_loss: 1.8224 - val_accuracy: 0.5788 - lr: 1.0000e-04\n","Epoch 61/5000\n","376/376 [==============================] - 58s 153ms/step - loss: 1.8210 - accuracy: 0.5448 - val_loss: 1.8247 - val_accuracy: 0.5788 - lr: 1.0000e-04\n","Epoch 62/5000\n","376/376 [==============================] - 56s 147ms/step - loss: 1.8162 - accuracy: 0.5458 - val_loss: 1.8190 - val_accuracy: 0.5718 - lr: 1.0000e-04\n","Epoch 63/5000\n","376/376 [==============================] - 55s 145ms/step - loss: 1.8103 - accuracy: 0.5488 - val_loss: 1.8086 - val_accuracy: 0.5732 - lr: 1.0000e-04\n","Epoch 64/5000\n","376/376 [==============================] - 52s 136ms/step - loss: 1.8060 - accuracy: 0.5450 - val_loss: 1.8087 - val_accuracy: 0.5809 - lr: 1.0000e-04\n","Epoch 65/5000\n","376/376 [==============================] - 57s 149ms/step - loss: 1.7926 - accuracy: 0.5568 - val_loss: 1.7979 - val_accuracy: 0.5795 - lr: 1.0000e-04\n","Epoch 66/5000\n","376/376 [==============================] - 52s 138ms/step - loss: 1.7842 - accuracy: 0.5590 - val_loss: 1.7870 - val_accuracy: 0.5760 - lr: 1.0000e-04\n","Epoch 67/5000\n","376/376 [==============================] - 52s 137ms/step - loss: 1.7707 - accuracy: 0.5581 - val_loss: 1.7945 - val_accuracy: 0.5725 - lr: 1.0000e-04\n","Epoch 68/5000\n","376/376 [==============================] - 52s 138ms/step - loss: 1.7797 - accuracy: 0.5606 - val_loss: 1.7831 - val_accuracy: 0.5781 - lr: 1.0000e-04\n","Epoch 69/5000\n","376/376 [==============================] - 50s 133ms/step - loss: 1.7615 - accuracy: 0.5610 - val_loss: 1.7824 - val_accuracy: 0.5704 - lr: 1.0000e-04\n","Epoch 70/5000\n","376/376 [==============================] - 47s 125ms/step - loss: 1.7459 - accuracy: 0.5610 - val_loss: 1.7735 - val_accuracy: 0.5788 - lr: 1.0000e-04\n","Epoch 71/5000\n","376/376 [==============================] - 47s 124ms/step - loss: 1.7383 - accuracy: 0.5715 - val_loss: 1.7665 - val_accuracy: 0.5851 - lr: 1.0000e-04\n","Epoch 72/5000\n","376/376 [==============================] - 50s 131ms/step - loss: 1.7211 - accuracy: 0.5741 - val_loss: 1.7577 - val_accuracy: 0.5915 - lr: 1.0000e-04\n","Epoch 73/5000\n","376/376 [==============================] - 47s 124ms/step - loss: 1.7468 - accuracy: 0.5661 - val_loss: 1.7547 - val_accuracy: 0.5844 - lr: 1.0000e-04\n","Epoch 74/5000\n","376/376 [==============================] - 44s 116ms/step - loss: 1.7161 - accuracy: 0.5711 - val_loss: 1.7618 - val_accuracy: 0.5851 - lr: 1.0000e-04\n","Epoch 75/5000\n","376/376 [==============================] - 46s 122ms/step - loss: 1.7227 - accuracy: 0.5610 - val_loss: 1.7476 - val_accuracy: 0.5922 - lr: 1.0000e-04\n","Epoch 76/5000\n","376/376 [==============================] - 47s 123ms/step - loss: 1.7164 - accuracy: 0.5670 - val_loss: 1.7491 - val_accuracy: 0.5893 - lr: 1.0000e-04\n","Epoch 77/5000\n","376/376 [==============================] - 45s 118ms/step - loss: 1.7130 - accuracy: 0.5756 - val_loss: 1.7415 - val_accuracy: 0.5915 - lr: 1.0000e-04\n","Epoch 78/5000\n","376/376 [==============================] - 46s 123ms/step - loss: 1.7000 - accuracy: 0.5700 - val_loss: 1.7369 - val_accuracy: 0.5879 - lr: 1.0000e-04\n","Epoch 79/5000\n","376/376 [==============================] - 44s 116ms/step - loss: 1.6850 - accuracy: 0.5758 - val_loss: 1.7412 - val_accuracy: 0.5865 - lr: 1.0000e-04\n","Epoch 80/5000\n","376/376 [==============================] - 44s 116ms/step - loss: 1.7123 - accuracy: 0.5683 - val_loss: 1.7285 - val_accuracy: 0.5872 - lr: 1.0000e-04\n","Epoch 81/5000\n","376/376 [==============================] - 44s 116ms/step - loss: 1.6924 - accuracy: 0.5721 - val_loss: 1.7244 - val_accuracy: 0.5915 - lr: 1.0000e-04\n","Epoch 82/5000\n","376/376 [==============================] - 43s 114ms/step - loss: 1.6860 - accuracy: 0.5781 - val_loss: 1.7213 - val_accuracy: 0.5964 - lr: 1.0000e-04\n","Epoch 83/5000\n","376/376 [==============================] - 43s 113ms/step - loss: 1.6820 - accuracy: 0.5759 - val_loss: 1.7175 - val_accuracy: 0.5893 - lr: 1.0000e-04\n","Epoch 84/5000\n","376/376 [==============================] - 43s 114ms/step - loss: 1.6708 - accuracy: 0.5834 - val_loss: 1.7105 - val_accuracy: 0.5922 - lr: 1.0000e-04\n","Epoch 85/5000\n","376/376 [==============================] - 41s 110ms/step - loss: 1.6645 - accuracy: 0.5843 - val_loss: 1.7185 - val_accuracy: 0.5844 - lr: 1.0000e-04\n","Epoch 86/5000\n","376/376 [==============================] - 43s 115ms/step - loss: 1.6529 - accuracy: 0.5853 - val_loss: 1.7055 - val_accuracy: 0.5922 - lr: 1.0000e-04\n","Epoch 87/5000\n","376/376 [==============================] - 43s 114ms/step - loss: 1.6491 - accuracy: 0.5898 - val_loss: 1.6984 - val_accuracy: 0.6020 - lr: 1.0000e-04\n","Epoch 88/5000\n","376/376 [==============================] - 43s 113ms/step - loss: 1.6463 - accuracy: 0.5869 - val_loss: 1.6954 - val_accuracy: 0.5985 - lr: 1.0000e-04\n","Epoch 89/5000\n","376/376 [==============================] - 42s 112ms/step - loss: 1.6398 - accuracy: 0.5888 - val_loss: 1.6935 - val_accuracy: 0.5985 - lr: 1.0000e-04\n","Epoch 90/5000\n","376/376 [==============================] - 41s 109ms/step - loss: 1.6368 - accuracy: 0.5854 - val_loss: 1.6859 - val_accuracy: 0.5957 - lr: 1.0000e-04\n","Epoch 91/5000\n","376/376 [==============================] - 42s 109ms/step - loss: 1.6414 - accuracy: 0.5896 - val_loss: 1.6854 - val_accuracy: 0.5999 - lr: 1.0000e-04\n","Epoch 92/5000\n","376/376 [==============================] - 42s 112ms/step - loss: 1.6335 - accuracy: 0.5889 - val_loss: 1.6766 - val_accuracy: 0.6027 - lr: 1.0000e-04\n","Epoch 93/5000\n","376/376 [==============================] - 41s 109ms/step - loss: 1.6171 - accuracy: 0.5922 - val_loss: 1.6858 - val_accuracy: 0.5964 - lr: 1.0000e-04\n","Epoch 94/5000\n","376/376 [==============================] - 40s 107ms/step - loss: 1.6106 - accuracy: 0.5947 - val_loss: 1.6760 - val_accuracy: 0.5929 - lr: 1.0000e-04\n","Epoch 95/5000\n","376/376 [==============================] - 41s 107ms/step - loss: 1.6275 - accuracy: 0.5922 - val_loss: 1.6688 - val_accuracy: 0.6020 - lr: 1.0000e-04\n","Epoch 96/5000\n","376/376 [==============================] - 40s 106ms/step - loss: 1.6173 - accuracy: 0.5941 - val_loss: 1.6676 - val_accuracy: 0.5964 - lr: 1.0000e-04\n","Epoch 97/5000\n","376/376 [==============================] - 41s 108ms/step - loss: 1.6160 - accuracy: 0.5922 - val_loss: 1.6674 - val_accuracy: 0.5985 - lr: 1.0000e-04\n","Epoch 98/5000\n","376/376 [==============================] - 40s 107ms/step - loss: 1.5999 - accuracy: 0.5942 - val_loss: 1.6528 - val_accuracy: 0.6048 - lr: 1.0000e-04\n","Epoch 99/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.5909 - accuracy: 0.6006 - val_loss: 1.6585 - val_accuracy: 0.5950 - lr: 1.0000e-04\n","Epoch 100/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.6031 - accuracy: 0.5984 - val_loss: 1.6561 - val_accuracy: 0.6020 - lr: 1.0000e-04\n","Epoch 101/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.5871 - accuracy: 0.5967 - val_loss: 1.6520 - val_accuracy: 0.6055 - lr: 1.0000e-04\n","Epoch 102/5000\n","376/376 [==============================] - 41s 108ms/step - loss: 1.5863 - accuracy: 0.5962 - val_loss: 1.6580 - val_accuracy: 0.5950 - lr: 1.0000e-04\n","Epoch 103/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.5794 - accuracy: 0.6016 - val_loss: 1.6447 - val_accuracy: 0.6055 - lr: 1.0000e-04\n","Epoch 104/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.5686 - accuracy: 0.6034 - val_loss: 1.6478 - val_accuracy: 0.6055 - lr: 1.0000e-04\n","Epoch 105/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.5870 - accuracy: 0.6004 - val_loss: 1.6455 - val_accuracy: 0.5985 - lr: 1.0000e-04\n","Epoch 106/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.5513 - accuracy: 0.6069 - val_loss: 1.6402 - val_accuracy: 0.6069 - lr: 1.0000e-04\n","Epoch 107/5000\n","376/376 [==============================] - 40s 106ms/step - loss: 1.5435 - accuracy: 0.6036 - val_loss: 1.6331 - val_accuracy: 0.6034 - lr: 1.0000e-04\n","Epoch 108/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.5494 - accuracy: 0.6089 - val_loss: 1.6434 - val_accuracy: 0.5999 - lr: 1.0000e-04\n","Epoch 109/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.5572 - accuracy: 0.6046 - val_loss: 1.6318 - val_accuracy: 0.6083 - lr: 1.0000e-04\n","Epoch 110/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.5472 - accuracy: 0.6105 - val_loss: 1.6360 - val_accuracy: 0.6055 - lr: 1.0000e-04\n","Epoch 111/5000\n","376/376 [==============================] - 40s 106ms/step - loss: 1.5304 - accuracy: 0.6127 - val_loss: 1.6326 - val_accuracy: 0.5971 - lr: 1.0000e-04\n","Epoch 112/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.5313 - accuracy: 0.6067 - val_loss: 1.6254 - val_accuracy: 0.6111 - lr: 1.0000e-04\n","Epoch 113/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.5256 - accuracy: 0.6145 - val_loss: 1.6241 - val_accuracy: 0.6069 - lr: 1.0000e-04\n","Epoch 114/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.5261 - accuracy: 0.6157 - val_loss: 1.6279 - val_accuracy: 0.6055 - lr: 1.0000e-04\n","Epoch 115/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.5348 - accuracy: 0.6089 - val_loss: 1.6095 - val_accuracy: 0.6083 - lr: 1.0000e-04\n","Epoch 116/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.5227 - accuracy: 0.6137 - val_loss: 1.6113 - val_accuracy: 0.6048 - lr: 1.0000e-04\n","Epoch 117/5000\n","376/376 [==============================] - 38s 102ms/step - loss: 1.5436 - accuracy: 0.6104 - val_loss: 1.6119 - val_accuracy: 0.6090 - lr: 1.0000e-04\n","Epoch 118/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.5252 - accuracy: 0.6061 - val_loss: 1.6138 - val_accuracy: 0.6041 - lr: 1.0000e-04\n","Epoch 119/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.5273 - accuracy: 0.6086 - val_loss: 1.6115 - val_accuracy: 0.6139 - lr: 1.0000e-04\n","Epoch 120/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.4988 - accuracy: 0.6215 - val_loss: 1.6141 - val_accuracy: 0.6062 - lr: 1.0000e-04\n","Epoch 121/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.4963 - accuracy: 0.6225 - val_loss: 1.6030 - val_accuracy: 0.6111 - lr: 1.0000e-04\n","Epoch 122/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.4916 - accuracy: 0.6179 - val_loss: 1.6042 - val_accuracy: 0.6083 - lr: 1.0000e-04\n","Epoch 123/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.4953 - accuracy: 0.6165 - val_loss: 1.6028 - val_accuracy: 0.6055 - lr: 1.0000e-04\n","Epoch 124/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.5011 - accuracy: 0.6190 - val_loss: 1.5975 - val_accuracy: 0.6090 - lr: 1.0000e-04\n","Epoch 125/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.5004 - accuracy: 0.6190 - val_loss: 1.5983 - val_accuracy: 0.6076 - lr: 1.0000e-04\n","Epoch 126/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.4870 - accuracy: 0.6222 - val_loss: 1.6018 - val_accuracy: 0.6034 - lr: 1.0000e-04\n","Epoch 127/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.4972 - accuracy: 0.6175 - val_loss: 1.5966 - val_accuracy: 0.6097 - lr: 1.0000e-04\n","Epoch 128/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.4911 - accuracy: 0.6149 - val_loss: 1.5873 - val_accuracy: 0.6188 - lr: 1.0000e-04\n","Epoch 129/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.4716 - accuracy: 0.6257 - val_loss: 1.5977 - val_accuracy: 0.6006 - lr: 1.0000e-04\n","Epoch 130/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.4950 - accuracy: 0.6162 - val_loss: 1.5803 - val_accuracy: 0.6132 - lr: 1.0000e-04\n","Epoch 131/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.4642 - accuracy: 0.6240 - val_loss: 1.5939 - val_accuracy: 0.6069 - lr: 1.0000e-04\n","Epoch 132/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.4478 - accuracy: 0.6328 - val_loss: 1.5862 - val_accuracy: 0.6104 - lr: 1.0000e-04\n","Epoch 133/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.4741 - accuracy: 0.6240 - val_loss: 1.5797 - val_accuracy: 0.6076 - lr: 1.0000e-04\n","Epoch 134/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.4695 - accuracy: 0.6209 - val_loss: 1.5743 - val_accuracy: 0.6174 - lr: 1.0000e-04\n","Epoch 135/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.4445 - accuracy: 0.6295 - val_loss: 1.5736 - val_accuracy: 0.6223 - lr: 1.0000e-04\n","Epoch 136/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.4525 - accuracy: 0.6275 - val_loss: 1.5792 - val_accuracy: 0.6062 - lr: 1.0000e-04\n","Epoch 137/5000\n","376/376 [==============================] - 38s 102ms/step - loss: 1.4650 - accuracy: 0.6282 - val_loss: 1.5685 - val_accuracy: 0.6167 - lr: 1.0000e-04\n","Epoch 138/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.4544 - accuracy: 0.6245 - val_loss: 1.5757 - val_accuracy: 0.6139 - lr: 1.0000e-04\n","Epoch 139/5000\n","376/376 [==============================] - 38s 102ms/step - loss: 1.4772 - accuracy: 0.6259 - val_loss: 1.5610 - val_accuracy: 0.6160 - lr: 1.0000e-04\n","Epoch 140/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.4618 - accuracy: 0.6275 - val_loss: 1.5721 - val_accuracy: 0.6160 - lr: 1.0000e-04\n","Epoch 141/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.4525 - accuracy: 0.6288 - val_loss: 1.5688 - val_accuracy: 0.6146 - lr: 1.0000e-04\n","Epoch 142/5000\n","376/376 [==============================] - 40s 106ms/step - loss: 1.4487 - accuracy: 0.6323 - val_loss: 1.5632 - val_accuracy: 0.6111 - lr: 1.0000e-04\n","Epoch 143/5000\n","376/376 [==============================] - 42s 110ms/step - loss: 1.4593 - accuracy: 0.6328 - val_loss: 1.5726 - val_accuracy: 0.6139 - lr: 1.0000e-04\n","Epoch 144/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.4427 - accuracy: 0.6322 - val_loss: 1.5644 - val_accuracy: 0.6181 - lr: 1.0000e-04\n","Epoch 145/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.4455 - accuracy: 0.6348 - val_loss: 1.5645 - val_accuracy: 0.6146 - lr: 1.0000e-04\n","Epoch 146/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.4181 - accuracy: 0.6383 - val_loss: 1.5588 - val_accuracy: 0.6209 - lr: 1.0000e-04\n","Epoch 147/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.4250 - accuracy: 0.6305 - val_loss: 1.5622 - val_accuracy: 0.6167 - lr: 1.0000e-04\n","Epoch 148/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.4161 - accuracy: 0.6375 - val_loss: 1.5565 - val_accuracy: 0.6097 - lr: 1.0000e-04\n","Epoch 149/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.4244 - accuracy: 0.6352 - val_loss: 1.5512 - val_accuracy: 0.6160 - lr: 1.0000e-04\n","Epoch 150/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.4164 - accuracy: 0.6345 - val_loss: 1.5522 - val_accuracy: 0.6167 - lr: 1.0000e-04\n","Epoch 151/5000\n","376/376 [==============================] - 40s 106ms/step - loss: 1.4221 - accuracy: 0.6377 - val_loss: 1.5507 - val_accuracy: 0.6209 - lr: 1.0000e-04\n","Epoch 152/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.4386 - accuracy: 0.6342 - val_loss: 1.5473 - val_accuracy: 0.6216 - lr: 1.0000e-04\n","Epoch 153/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.4208 - accuracy: 0.6307 - val_loss: 1.5623 - val_accuracy: 0.6132 - lr: 1.0000e-04\n","Epoch 154/5000\n","376/376 [==============================] - 38s 102ms/step - loss: 1.4121 - accuracy: 0.6385 - val_loss: 1.5397 - val_accuracy: 0.6279 - lr: 1.0000e-04\n","Epoch 155/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.4288 - accuracy: 0.6335 - val_loss: 1.5433 - val_accuracy: 0.6237 - lr: 1.0000e-04\n","Epoch 156/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.4058 - accuracy: 0.6392 - val_loss: 1.5459 - val_accuracy: 0.6195 - lr: 1.0000e-04\n","Epoch 157/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3966 - accuracy: 0.6473 - val_loss: 1.5416 - val_accuracy: 0.6174 - lr: 1.0000e-04\n","Epoch 158/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.4166 - accuracy: 0.6345 - val_loss: 1.5457 - val_accuracy: 0.6202 - lr: 1.0000e-04\n","Epoch 159/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.4067 - accuracy: 0.6352 - val_loss: 1.5333 - val_accuracy: 0.6216 - lr: 1.0000e-04\n","Epoch 160/5000\n","376/376 [==============================] - 38s 102ms/step - loss: 1.3915 - accuracy: 0.6438 - val_loss: 1.5326 - val_accuracy: 0.6251 - lr: 1.0000e-04\n","Epoch 161/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3873 - accuracy: 0.6478 - val_loss: 1.5402 - val_accuracy: 0.6174 - lr: 1.0000e-04\n","Epoch 162/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.4024 - accuracy: 0.6378 - val_loss: 1.5371 - val_accuracy: 0.6195 - lr: 1.0000e-04\n","Epoch 163/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.3848 - accuracy: 0.6465 - val_loss: 1.5324 - val_accuracy: 0.6188 - lr: 1.0000e-04\n","Epoch 164/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.3836 - accuracy: 0.6438 - val_loss: 1.5293 - val_accuracy: 0.6265 - lr: 1.0000e-04\n","Epoch 165/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3982 - accuracy: 0.6377 - val_loss: 1.5285 - val_accuracy: 0.6244 - lr: 1.0000e-04\n","Epoch 166/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3726 - accuracy: 0.6445 - val_loss: 1.5316 - val_accuracy: 0.6216 - lr: 1.0000e-04\n","Epoch 167/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.3838 - accuracy: 0.6495 - val_loss: 1.5277 - val_accuracy: 0.6258 - lr: 1.0000e-04\n","Epoch 168/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.3692 - accuracy: 0.6465 - val_loss: 1.5251 - val_accuracy: 0.6272 - lr: 1.0000e-04\n","Epoch 169/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.3958 - accuracy: 0.6385 - val_loss: 1.5312 - val_accuracy: 0.6258 - lr: 1.0000e-04\n","Epoch 170/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.3899 - accuracy: 0.6420 - val_loss: 1.5233 - val_accuracy: 0.6279 - lr: 1.0000e-04\n","Epoch 171/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3881 - accuracy: 0.6397 - val_loss: 1.5286 - val_accuracy: 0.6209 - lr: 1.0000e-04\n","Epoch 172/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.3612 - accuracy: 0.6483 - val_loss: 1.5188 - val_accuracy: 0.6307 - lr: 1.0000e-04\n","Epoch 173/5000\n","376/376 [==============================] - 38s 102ms/step - loss: 1.3590 - accuracy: 0.6530 - val_loss: 1.5134 - val_accuracy: 0.6286 - lr: 1.0000e-04\n","Epoch 174/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3683 - accuracy: 0.6493 - val_loss: 1.5164 - val_accuracy: 0.6265 - lr: 1.0000e-04\n","Epoch 175/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.3509 - accuracy: 0.6440 - val_loss: 1.5271 - val_accuracy: 0.6195 - lr: 1.0000e-04\n","Epoch 176/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3855 - accuracy: 0.6390 - val_loss: 1.5163 - val_accuracy: 0.6272 - lr: 1.0000e-04\n","Epoch 177/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.3644 - accuracy: 0.6481 - val_loss: 1.5186 - val_accuracy: 0.6237 - lr: 1.0000e-04\n","Epoch 178/5000\n","376/376 [==============================] - 38s 102ms/step - loss: 1.3549 - accuracy: 0.6526 - val_loss: 1.5085 - val_accuracy: 0.6335 - lr: 1.0000e-04\n","Epoch 179/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3397 - accuracy: 0.6578 - val_loss: 1.5223 - val_accuracy: 0.6209 - lr: 1.0000e-04\n","Epoch 180/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.3779 - accuracy: 0.6486 - val_loss: 1.5110 - val_accuracy: 0.6216 - lr: 1.0000e-04\n","Epoch 181/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.3545 - accuracy: 0.6570 - val_loss: 1.5142 - val_accuracy: 0.6244 - lr: 1.0000e-04\n","Epoch 182/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.3516 - accuracy: 0.6478 - val_loss: 1.5138 - val_accuracy: 0.6251 - lr: 1.0000e-04\n","Epoch 183/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.3540 - accuracy: 0.6508 - val_loss: 1.5129 - val_accuracy: 0.6202 - lr: 1.0000e-04\n","Epoch 184/5000\n","376/376 [==============================] - 38s 102ms/step - loss: 1.3441 - accuracy: 0.6543 - val_loss: 1.5056 - val_accuracy: 0.6307 - lr: 1.0000e-04\n","Epoch 185/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.3332 - accuracy: 0.6563 - val_loss: 1.5153 - val_accuracy: 0.6223 - lr: 1.0000e-04\n","Epoch 186/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3610 - accuracy: 0.6466 - val_loss: 1.5049 - val_accuracy: 0.6321 - lr: 1.0000e-04\n","Epoch 187/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.3397 - accuracy: 0.6523 - val_loss: 1.5008 - val_accuracy: 0.6251 - lr: 1.0000e-04\n","Epoch 188/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3412 - accuracy: 0.6533 - val_loss: 1.4955 - val_accuracy: 0.6335 - lr: 1.0000e-04\n","Epoch 189/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3235 - accuracy: 0.6595 - val_loss: 1.4948 - val_accuracy: 0.6356 - lr: 1.0000e-04\n","Epoch 190/5000\n","376/376 [==============================] - 38s 102ms/step - loss: 1.3341 - accuracy: 0.6533 - val_loss: 1.4928 - val_accuracy: 0.6328 - lr: 1.0000e-04\n","Epoch 191/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.3390 - accuracy: 0.6515 - val_loss: 1.4994 - val_accuracy: 0.6314 - lr: 1.0000e-04\n","Epoch 192/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3250 - accuracy: 0.6513 - val_loss: 1.4990 - val_accuracy: 0.6328 - lr: 1.0000e-04\n","Epoch 193/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.3232 - accuracy: 0.6531 - val_loss: 1.4963 - val_accuracy: 0.6314 - lr: 1.0000e-04\n","Epoch 194/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3302 - accuracy: 0.6540 - val_loss: 1.4880 - val_accuracy: 0.6300 - lr: 1.0000e-04\n","Epoch 195/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.3228 - accuracy: 0.6530 - val_loss: 1.4908 - val_accuracy: 0.6307 - lr: 1.0000e-04\n","Epoch 196/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.3168 - accuracy: 0.6593 - val_loss: 1.4878 - val_accuracy: 0.6314 - lr: 1.0000e-04\n","Epoch 197/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3352 - accuracy: 0.6493 - val_loss: 1.4851 - val_accuracy: 0.6370 - lr: 1.0000e-04\n","Epoch 198/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3286 - accuracy: 0.6565 - val_loss: 1.4816 - val_accuracy: 0.6363 - lr: 1.0000e-04\n","Epoch 199/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3068 - accuracy: 0.6596 - val_loss: 1.4862 - val_accuracy: 0.6321 - lr: 1.0000e-04\n","Epoch 200/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.3314 - accuracy: 0.6551 - val_loss: 1.4836 - val_accuracy: 0.6307 - lr: 1.0000e-04\n","Epoch 201/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.2934 - accuracy: 0.6638 - val_loss: 1.4795 - val_accuracy: 0.6356 - lr: 1.0000e-04\n","Epoch 202/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3201 - accuracy: 0.6575 - val_loss: 1.4835 - val_accuracy: 0.6314 - lr: 1.0000e-04\n","Epoch 203/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.3119 - accuracy: 0.6611 - val_loss: 1.4837 - val_accuracy: 0.6321 - lr: 1.0000e-04\n","Epoch 204/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.3066 - accuracy: 0.6623 - val_loss: 1.4808 - val_accuracy: 0.6335 - lr: 1.0000e-04\n","Epoch 205/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3176 - accuracy: 0.6580 - val_loss: 1.4866 - val_accuracy: 0.6384 - lr: 1.0000e-04\n","Epoch 206/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.3183 - accuracy: 0.6618 - val_loss: 1.4764 - val_accuracy: 0.6349 - lr: 1.0000e-04\n","Epoch 207/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3120 - accuracy: 0.6590 - val_loss: 1.4785 - val_accuracy: 0.6321 - lr: 1.0000e-04\n","Epoch 208/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2997 - accuracy: 0.6668 - val_loss: 1.4717 - val_accuracy: 0.6412 - lr: 1.0000e-04\n","Epoch 209/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3195 - accuracy: 0.6551 - val_loss: 1.4846 - val_accuracy: 0.6377 - lr: 1.0000e-04\n","Epoch 210/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2987 - accuracy: 0.6516 - val_loss: 1.4745 - val_accuracy: 0.6377 - lr: 1.0000e-04\n","Epoch 211/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2825 - accuracy: 0.6738 - val_loss: 1.4779 - val_accuracy: 0.6349 - lr: 1.0000e-04\n","Epoch 212/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.3026 - accuracy: 0.6585 - val_loss: 1.4722 - val_accuracy: 0.6307 - lr: 1.0000e-04\n","Epoch 213/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.3043 - accuracy: 0.6633 - val_loss: 1.4725 - val_accuracy: 0.6342 - lr: 1.0000e-04\n","Epoch 214/5000\n","376/376 [==============================] - 38s 99ms/step - loss: 1.2892 - accuracy: 0.6706 - val_loss: 1.4792 - val_accuracy: 0.6328 - lr: 1.0000e-04\n","Epoch 215/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.2992 - accuracy: 0.6641 - val_loss: 1.4768 - val_accuracy: 0.6335 - lr: 1.0000e-04\n","Epoch 216/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2853 - accuracy: 0.6651 - val_loss: 1.4658 - val_accuracy: 0.6363 - lr: 1.0000e-04\n","Epoch 217/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2705 - accuracy: 0.6699 - val_loss: 1.4701 - val_accuracy: 0.6328 - lr: 1.0000e-04\n","Epoch 218/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.2886 - accuracy: 0.6689 - val_loss: 1.4790 - val_accuracy: 0.6363 - lr: 1.0000e-04\n","Epoch 219/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.2992 - accuracy: 0.6591 - val_loss: 1.4689 - val_accuracy: 0.6321 - lr: 1.0000e-04\n","Epoch 220/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.2977 - accuracy: 0.6530 - val_loss: 1.4745 - val_accuracy: 0.6370 - lr: 1.0000e-04\n","Epoch 221/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2823 - accuracy: 0.6613 - val_loss: 1.4688 - val_accuracy: 0.6405 - lr: 1.0000e-04\n","Epoch 222/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.2918 - accuracy: 0.6648 - val_loss: 1.4692 - val_accuracy: 0.6370 - lr: 1.0000e-04\n","Epoch 223/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2879 - accuracy: 0.6615 - val_loss: 1.4616 - val_accuracy: 0.6349 - lr: 1.0000e-04\n","Epoch 224/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2834 - accuracy: 0.6673 - val_loss: 1.4692 - val_accuracy: 0.6328 - lr: 1.0000e-04\n","Epoch 225/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.2754 - accuracy: 0.6649 - val_loss: 1.4702 - val_accuracy: 0.6321 - lr: 1.0000e-04\n","Epoch 226/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2826 - accuracy: 0.6691 - val_loss: 1.4596 - val_accuracy: 0.6405 - lr: 1.0000e-04\n","Epoch 227/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2720 - accuracy: 0.6646 - val_loss: 1.4642 - val_accuracy: 0.6356 - lr: 1.0000e-04\n","Epoch 228/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2728 - accuracy: 0.6753 - val_loss: 1.4621 - val_accuracy: 0.6363 - lr: 1.0000e-04\n","Epoch 229/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.2745 - accuracy: 0.6709 - val_loss: 1.4635 - val_accuracy: 0.6398 - lr: 1.0000e-04\n","Epoch 230/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.2830 - accuracy: 0.6676 - val_loss: 1.4567 - val_accuracy: 0.6412 - lr: 1.0000e-04\n","Epoch 231/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2759 - accuracy: 0.6699 - val_loss: 1.4648 - val_accuracy: 0.6412 - lr: 1.0000e-04\n","Epoch 232/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.2856 - accuracy: 0.6635 - val_loss: 1.4664 - val_accuracy: 0.6391 - lr: 1.0000e-04\n","Epoch 233/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.2615 - accuracy: 0.6736 - val_loss: 1.4691 - val_accuracy: 0.6419 - lr: 1.0000e-04\n","Epoch 234/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.2921 - accuracy: 0.6636 - val_loss: 1.4609 - val_accuracy: 0.6363 - lr: 1.0000e-04\n","Epoch 235/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2746 - accuracy: 0.6671 - val_loss: 1.4513 - val_accuracy: 0.6405 - lr: 1.0000e-04\n","Epoch 236/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2841 - accuracy: 0.6676 - val_loss: 1.4523 - val_accuracy: 0.6370 - lr: 1.0000e-04\n","Epoch 237/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2547 - accuracy: 0.6729 - val_loss: 1.4492 - val_accuracy: 0.6454 - lr: 1.0000e-04\n","Epoch 238/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2691 - accuracy: 0.6699 - val_loss: 1.4524 - val_accuracy: 0.6363 - lr: 1.0000e-04\n","Epoch 239/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.2478 - accuracy: 0.6739 - val_loss: 1.4547 - val_accuracy: 0.6377 - lr: 1.0000e-04\n","Epoch 240/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2471 - accuracy: 0.6721 - val_loss: 1.4550 - val_accuracy: 0.6398 - lr: 1.0000e-04\n","Epoch 241/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2649 - accuracy: 0.6729 - val_loss: 1.4452 - val_accuracy: 0.6412 - lr: 1.0000e-04\n","Epoch 242/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2470 - accuracy: 0.6714 - val_loss: 1.4477 - val_accuracy: 0.6384 - lr: 1.0000e-04\n","Epoch 243/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.2439 - accuracy: 0.6786 - val_loss: 1.4514 - val_accuracy: 0.6363 - lr: 1.0000e-04\n","Epoch 244/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.2696 - accuracy: 0.6731 - val_loss: 1.4572 - val_accuracy: 0.6440 - lr: 1.0000e-04\n","Epoch 245/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.2662 - accuracy: 0.6668 - val_loss: 1.4498 - val_accuracy: 0.6440 - lr: 1.0000e-04\n","Epoch 246/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.2660 - accuracy: 0.6699 - val_loss: 1.4506 - val_accuracy: 0.6412 - lr: 1.0000e-04\n","Epoch 247/5000\n","376/376 [==============================] - 38s 101ms/step - loss: 1.2522 - accuracy: 0.6741 - val_loss: 1.4477 - val_accuracy: 0.6370 - lr: 1.0000e-04\n","Epoch 248/5000\n","376/376 [==============================] - 38s 102ms/step - loss: 1.2634 - accuracy: 0.6746 - val_loss: 1.4563 - val_accuracy: 0.6398 - lr: 1.0000e-04\n","Epoch 249/5000\n","376/376 [==============================] - 48s 128ms/step - loss: 1.2432 - accuracy: 0.6706 - val_loss: 1.4437 - val_accuracy: 0.6433 - lr: 1.0000e-04\n","Epoch 250/5000\n","376/376 [==============================] - 47s 125ms/step - loss: 1.2320 - accuracy: 0.6804 - val_loss: 1.4460 - val_accuracy: 0.6482 - lr: 1.0000e-04\n","Epoch 251/5000\n","376/376 [==============================] - 47s 123ms/step - loss: 1.2274 - accuracy: 0.6758 - val_loss: 1.4452 - val_accuracy: 0.6447 - lr: 1.0000e-04\n","Epoch 252/5000\n","376/376 [==============================] - 47s 125ms/step - loss: 1.2388 - accuracy: 0.6756 - val_loss: 1.4538 - val_accuracy: 0.6384 - lr: 1.0000e-04\n","Epoch 253/5000\n","376/376 [==============================] - 48s 126ms/step - loss: 1.2256 - accuracy: 0.6771 - val_loss: 1.4461 - val_accuracy: 0.6426 - lr: 1.0000e-04\n","Epoch 254/5000\n","376/376 [==============================] - 48s 126ms/step - loss: 1.2491 - accuracy: 0.6718 - val_loss: 1.4417 - val_accuracy: 0.6447 - lr: 1.0000e-04\n","Epoch 255/5000\n","376/376 [==============================] - 47s 125ms/step - loss: 1.2293 - accuracy: 0.6728 - val_loss: 1.4407 - val_accuracy: 0.6426 - lr: 1.0000e-04\n","Epoch 256/5000\n","376/376 [==============================] - 46s 123ms/step - loss: 1.2301 - accuracy: 0.6806 - val_loss: 1.4428 - val_accuracy: 0.6363 - lr: 1.0000e-04\n","Epoch 257/5000\n","376/376 [==============================] - 47s 124ms/step - loss: 1.2409 - accuracy: 0.6784 - val_loss: 1.4361 - val_accuracy: 0.6412 - lr: 1.0000e-04\n","Epoch 258/5000\n","376/376 [==============================] - 47s 123ms/step - loss: 1.2344 - accuracy: 0.6759 - val_loss: 1.4458 - val_accuracy: 0.6349 - lr: 1.0000e-04\n","Epoch 259/5000\n","376/376 [==============================] - 46s 122ms/step - loss: 1.2311 - accuracy: 0.6826 - val_loss: 1.4447 - val_accuracy: 0.6405 - lr: 1.0000e-04\n","Epoch 260/5000\n","376/376 [==============================] - 47s 124ms/step - loss: 1.2454 - accuracy: 0.6713 - val_loss: 1.4433 - val_accuracy: 0.6426 - lr: 1.0000e-04\n","Epoch 261/5000\n","376/376 [==============================] - 47s 123ms/step - loss: 1.2309 - accuracy: 0.6743 - val_loss: 1.4439 - val_accuracy: 0.6405 - lr: 1.0000e-04\n","Epoch 262/5000\n","376/376 [==============================] - 47s 124ms/step - loss: 1.2275 - accuracy: 0.6773 - val_loss: 1.4436 - val_accuracy: 0.6391 - lr: 1.0000e-04\n","Epoch 263/5000\n","376/376 [==============================] - 47s 123ms/step - loss: 1.2341 - accuracy: 0.6761 - val_loss: 1.4386 - val_accuracy: 0.6461 - lr: 1.0000e-04\n","Epoch 264/5000\n","376/376 [==============================] - 48s 127ms/step - loss: 1.2416 - accuracy: 0.6753 - val_loss: 1.4427 - val_accuracy: 0.6419 - lr: 1.0000e-04\n","Epoch 265/5000\n","375/376 [============================>.] - ETA: 0s - loss: 1.2195 - accuracy: 0.6810\n","Epoch 265: ReduceLROnPlateau reducing learning rate to 7.499999810534064e-05.\n","376/376 [==============================] - 47s 124ms/step - loss: 1.2197 - accuracy: 0.6808 - val_loss: 1.4403 - val_accuracy: 0.6433 - lr: 1.0000e-04\n","Epoch 266/5000\n","376/376 [==============================] - 48s 128ms/step - loss: 1.2229 - accuracy: 0.6783 - val_loss: 1.4410 - val_accuracy: 0.6447 - lr: 7.5000e-05\n","Epoch 267/5000\n","376/376 [==============================] - 46s 121ms/step - loss: 1.2043 - accuracy: 0.6874 - val_loss: 1.4390 - val_accuracy: 0.6454 - lr: 7.5000e-05\n","Epoch 268/5000\n","376/376 [==============================] - 45s 119ms/step - loss: 1.2157 - accuracy: 0.6804 - val_loss: 1.4363 - val_accuracy: 0.6426 - lr: 7.5000e-05\n","Epoch 269/5000\n","376/376 [==============================] - 45s 119ms/step - loss: 1.2172 - accuracy: 0.6786 - val_loss: 1.4371 - val_accuracy: 0.6503 - lr: 7.5000e-05\n","Epoch 270/5000\n","376/376 [==============================] - 45s 119ms/step - loss: 1.2078 - accuracy: 0.6768 - val_loss: 1.4368 - val_accuracy: 0.6419 - lr: 7.5000e-05\n","Epoch 271/5000\n","376/376 [==============================] - 45s 119ms/step - loss: 1.2180 - accuracy: 0.6761 - val_loss: 1.4379 - val_accuracy: 0.6447 - lr: 7.5000e-05\n","Epoch 272/5000\n","376/376 [==============================] - 46s 121ms/step - loss: 1.2204 - accuracy: 0.6776 - val_loss: 1.4357 - val_accuracy: 0.6405 - lr: 7.5000e-05\n","Epoch 273/5000\n","376/376 [==============================] - 45s 120ms/step - loss: 1.2095 - accuracy: 0.6832 - val_loss: 1.4407 - val_accuracy: 0.6489 - lr: 7.5000e-05\n","Epoch 274/5000\n","376/376 [==============================] - 45s 119ms/step - loss: 1.2023 - accuracy: 0.6791 - val_loss: 1.4381 - val_accuracy: 0.6426 - lr: 7.5000e-05\n","Epoch 275/5000\n","376/376 [==============================] - 47s 125ms/step - loss: 1.2155 - accuracy: 0.6786 - val_loss: 1.4296 - val_accuracy: 0.6433 - lr: 7.5000e-05\n","Epoch 276/5000\n","376/376 [==============================] - 45s 119ms/step - loss: 1.2023 - accuracy: 0.6852 - val_loss: 1.4287 - val_accuracy: 0.6510 - lr: 7.5000e-05\n","Epoch 277/5000\n","376/376 [==============================] - 44s 116ms/step - loss: 1.2176 - accuracy: 0.6769 - val_loss: 1.4257 - val_accuracy: 0.6475 - lr: 7.5000e-05\n","Epoch 278/5000\n","376/376 [==============================] - 44s 116ms/step - loss: 1.2109 - accuracy: 0.6862 - val_loss: 1.4254 - val_accuracy: 0.6496 - lr: 7.5000e-05\n","Epoch 279/5000\n","376/376 [==============================] - 44s 116ms/step - loss: 1.2075 - accuracy: 0.6894 - val_loss: 1.4330 - val_accuracy: 0.6489 - lr: 7.5000e-05\n","Epoch 280/5000\n","376/376 [==============================] - 43s 114ms/step - loss: 1.1934 - accuracy: 0.6837 - val_loss: 1.4365 - val_accuracy: 0.6412 - lr: 7.5000e-05\n","Epoch 281/5000\n","376/376 [==============================] - 43s 113ms/step - loss: 1.2091 - accuracy: 0.6819 - val_loss: 1.4262 - val_accuracy: 0.6468 - lr: 7.5000e-05\n","Epoch 282/5000\n","376/376 [==============================] - 43s 115ms/step - loss: 1.1935 - accuracy: 0.6826 - val_loss: 1.4277 - val_accuracy: 0.6454 - lr: 7.5000e-05\n","Epoch 283/5000\n","376/376 [==============================] - 43s 113ms/step - loss: 1.2079 - accuracy: 0.6819 - val_loss: 1.4323 - val_accuracy: 0.6454 - lr: 7.5000e-05\n","Epoch 284/5000\n","376/376 [==============================] - 42s 112ms/step - loss: 1.1977 - accuracy: 0.6882 - val_loss: 1.4328 - val_accuracy: 0.6454 - lr: 7.5000e-05\n","Epoch 285/5000\n","376/376 [==============================] - 43s 112ms/step - loss: 1.2103 - accuracy: 0.6769 - val_loss: 1.4262 - val_accuracy: 0.6468 - lr: 7.5000e-05\n","Epoch 286/5000\n","375/376 [============================>.] - ETA: 0s - loss: 1.1985 - accuracy: 0.6825\n","Epoch 286: ReduceLROnPlateau reducing learning rate to 5.6249997214763425e-05.\n","376/376 [==============================] - 43s 114ms/step - loss: 1.1986 - accuracy: 0.6822 - val_loss: 1.4287 - val_accuracy: 0.6447 - lr: 7.5000e-05\n","Epoch 287/5000\n","376/376 [==============================] - 43s 114ms/step - loss: 1.1972 - accuracy: 0.6906 - val_loss: 1.4237 - val_accuracy: 0.6454 - lr: 5.6250e-05\n","Epoch 288/5000\n","376/376 [==============================] - 43s 114ms/step - loss: 1.1926 - accuracy: 0.6849 - val_loss: 1.4266 - val_accuracy: 0.6468 - lr: 5.6250e-05\n","Epoch 289/5000\n","376/376 [==============================] - 43s 114ms/step - loss: 1.2036 - accuracy: 0.6763 - val_loss: 1.4285 - val_accuracy: 0.6440 - lr: 5.6250e-05\n","Epoch 290/5000\n","376/376 [==============================] - 43s 114ms/step - loss: 1.1849 - accuracy: 0.6879 - val_loss: 1.4223 - val_accuracy: 0.6545 - lr: 5.6250e-05\n","Epoch 291/5000\n","376/376 [==============================] - 44s 116ms/step - loss: 1.1982 - accuracy: 0.6857 - val_loss: 1.4280 - val_accuracy: 0.6447 - lr: 5.6250e-05\n","Epoch 292/5000\n","376/376 [==============================] - 42s 111ms/step - loss: 1.1998 - accuracy: 0.6864 - val_loss: 1.4219 - val_accuracy: 0.6517 - lr: 5.6250e-05\n","Epoch 293/5000\n","376/376 [==============================] - 43s 113ms/step - loss: 1.1951 - accuracy: 0.6872 - val_loss: 1.4183 - val_accuracy: 0.6503 - lr: 5.6250e-05\n","Epoch 294/5000\n","376/376 [==============================] - 44s 116ms/step - loss: 1.2149 - accuracy: 0.6799 - val_loss: 1.4242 - val_accuracy: 0.6510 - lr: 5.6250e-05\n","Epoch 295/5000\n","376/376 [==============================] - 44s 116ms/step - loss: 1.1882 - accuracy: 0.6862 - val_loss: 1.4228 - val_accuracy: 0.6503 - lr: 5.6250e-05\n","Epoch 296/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.1816 - accuracy: 0.6914 - val_loss: 1.4203 - val_accuracy: 0.6559 - lr: 5.6250e-05\n","Epoch 297/5000\n","376/376 [==============================] - 40s 107ms/step - loss: 1.1990 - accuracy: 0.6872 - val_loss: 1.4296 - val_accuracy: 0.6496 - lr: 5.6250e-05\n","Epoch 298/5000\n","376/376 [==============================] - 40s 107ms/step - loss: 1.1807 - accuracy: 0.6916 - val_loss: 1.4254 - val_accuracy: 0.6461 - lr: 5.6250e-05\n","Epoch 299/5000\n","376/376 [==============================] - 37s 98ms/step - loss: 1.2123 - accuracy: 0.6824 - val_loss: 1.4229 - val_accuracy: 0.6496 - lr: 5.6250e-05\n","Epoch 300/5000\n","376/376 [==============================] - 38s 100ms/step - loss: 1.2096 - accuracy: 0.6786 - val_loss: 1.4251 - val_accuracy: 0.6468 - lr: 5.6250e-05\n","Epoch 301/5000\n","376/376 [==============================] - ETA: 0s - loss: 1.1724 - accuracy: 0.6884\n","Epoch 301: ReduceLROnPlateau reducing learning rate to 4.218749927531462e-05.\n","376/376 [==============================] - 41s 109ms/step - loss: 1.1724 - accuracy: 0.6884 - val_loss: 1.4208 - val_accuracy: 0.6524 - lr: 5.6250e-05\n","Epoch 302/5000\n","376/376 [==============================] - 43s 114ms/step - loss: 1.1867 - accuracy: 0.6894 - val_loss: 1.4221 - val_accuracy: 0.6496 - lr: 4.2188e-05\n","Epoch 303/5000\n","376/376 [==============================] - 41s 107ms/step - loss: 1.1811 - accuracy: 0.6876 - val_loss: 1.4211 - val_accuracy: 0.6503 - lr: 4.2188e-05\n","Epoch 304/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.1993 - accuracy: 0.6809 - val_loss: 1.4232 - val_accuracy: 0.6510 - lr: 4.2188e-05\n","Epoch 305/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.1918 - accuracy: 0.6809 - val_loss: 1.4210 - val_accuracy: 0.6503 - lr: 4.2188e-05\n","Epoch 306/5000\n","376/376 [==============================] - 41s 109ms/step - loss: 1.1722 - accuracy: 0.6909 - val_loss: 1.4189 - val_accuracy: 0.6517 - lr: 4.2188e-05\n","Epoch 307/5000\n","376/376 [==============================] - 44s 117ms/step - loss: 1.1832 - accuracy: 0.6866 - val_loss: 1.4237 - val_accuracy: 0.6496 - lr: 4.2188e-05\n","Epoch 308/5000\n","376/376 [==============================] - 47s 125ms/step - loss: 1.1876 - accuracy: 0.6929 - val_loss: 1.4221 - val_accuracy: 0.6510 - lr: 4.2188e-05\n","Epoch 309/5000\n","376/376 [==============================] - 47s 124ms/step - loss: 1.2020 - accuracy: 0.6837 - val_loss: 1.4179 - val_accuracy: 0.6468 - lr: 4.2188e-05\n","Epoch 310/5000\n","376/376 [==============================] - 47s 125ms/step - loss: 1.1979 - accuracy: 0.6867 - val_loss: 1.4216 - val_accuracy: 0.6475 - lr: 4.2188e-05\n","Epoch 311/5000\n","376/376 [==============================] - 45s 118ms/step - loss: 1.1667 - accuracy: 0.6884 - val_loss: 1.4241 - val_accuracy: 0.6489 - lr: 4.2188e-05\n","Epoch 312/5000\n","376/376 [==============================] - 45s 120ms/step - loss: 1.1929 - accuracy: 0.6886 - val_loss: 1.4256 - val_accuracy: 0.6454 - lr: 4.2188e-05\n","Epoch 313/5000\n","376/376 [==============================] - 42s 112ms/step - loss: 1.1850 - accuracy: 0.6912 - val_loss: 1.4192 - val_accuracy: 0.6510 - lr: 4.2188e-05\n","Epoch 314/5000\n","376/376 [==============================] - 41s 110ms/step - loss: 1.1764 - accuracy: 0.6901 - val_loss: 1.4193 - val_accuracy: 0.6517 - lr: 4.2188e-05\n","Epoch 315/5000\n","376/376 [==============================] - 43s 114ms/step - loss: 1.1807 - accuracy: 0.6869 - val_loss: 1.4239 - val_accuracy: 0.6433 - lr: 4.2188e-05\n","Epoch 316/5000\n","376/376 [==============================] - 44s 116ms/step - loss: 1.1832 - accuracy: 0.6879 - val_loss: 1.4165 - val_accuracy: 0.6496 - lr: 4.2188e-05\n","Epoch 317/5000\n","376/376 [==============================] - 43s 113ms/step - loss: 1.1878 - accuracy: 0.6871 - val_loss: 1.4217 - val_accuracy: 0.6510 - lr: 4.2188e-05\n","Epoch 318/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.1767 - accuracy: 0.6884 - val_loss: 1.4183 - val_accuracy: 0.6496 - lr: 4.2188e-05\n","Epoch 319/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.1907 - accuracy: 0.6832 - val_loss: 1.4176 - val_accuracy: 0.6496 - lr: 4.2188e-05\n","Epoch 320/5000\n","376/376 [==============================] - 43s 114ms/step - loss: 1.1705 - accuracy: 0.6927 - val_loss: 1.4174 - val_accuracy: 0.6496 - lr: 4.2188e-05\n","Epoch 321/5000\n","376/376 [==============================] - 40s 107ms/step - loss: 1.1868 - accuracy: 0.6892 - val_loss: 1.4217 - val_accuracy: 0.6489 - lr: 4.2188e-05\n","Epoch 322/5000\n","376/376 [==============================] - 43s 113ms/step - loss: 1.1877 - accuracy: 0.6821 - val_loss: 1.4233 - val_accuracy: 0.6482 - lr: 4.2188e-05\n","Epoch 323/5000\n","376/376 [==============================] - 42s 111ms/step - loss: 1.1961 - accuracy: 0.6856 - val_loss: 1.4174 - val_accuracy: 0.6496 - lr: 4.2188e-05\n","Epoch 324/5000\n","375/376 [============================>.] - ETA: 0s - loss: 1.1814 - accuracy: 0.6892\n","Epoch 324: ReduceLROnPlateau reducing learning rate to 3.164062582072802e-05.\n","376/376 [==============================] - 40s 106ms/step - loss: 1.1807 - accuracy: 0.6896 - val_loss: 1.4201 - val_accuracy: 0.6510 - lr: 4.2188e-05\n","Epoch 325/5000\n","376/376 [==============================] - 42s 111ms/step - loss: 1.1797 - accuracy: 0.6911 - val_loss: 1.4157 - val_accuracy: 0.6524 - lr: 3.1641e-05\n","Epoch 326/5000\n","376/376 [==============================] - 46s 122ms/step - loss: 1.1819 - accuracy: 0.6894 - val_loss: 1.4163 - val_accuracy: 0.6517 - lr: 3.1641e-05\n","Epoch 327/5000\n","376/376 [==============================] - 49s 131ms/step - loss: 1.1832 - accuracy: 0.6856 - val_loss: 1.4189 - val_accuracy: 0.6482 - lr: 3.1641e-05\n","Epoch 328/5000\n","376/376 [==============================] - 43s 112ms/step - loss: 1.1782 - accuracy: 0.6937 - val_loss: 1.4159 - val_accuracy: 0.6496 - lr: 3.1641e-05\n","Epoch 329/5000\n","376/376 [==============================] - 47s 126ms/step - loss: 1.1802 - accuracy: 0.6824 - val_loss: 1.4146 - val_accuracy: 0.6496 - lr: 3.1641e-05\n","Epoch 330/5000\n","376/376 [==============================] - 49s 130ms/step - loss: 1.1712 - accuracy: 0.6944 - val_loss: 1.4177 - val_accuracy: 0.6510 - lr: 3.1641e-05\n","Epoch 331/5000\n","376/376 [==============================] - 48s 128ms/step - loss: 1.1870 - accuracy: 0.6862 - val_loss: 1.4135 - val_accuracy: 0.6517 - lr: 3.1641e-05\n","Epoch 332/5000\n","376/376 [==============================] - 48s 128ms/step - loss: 1.1884 - accuracy: 0.6824 - val_loss: 1.4183 - val_accuracy: 0.6496 - lr: 3.1641e-05\n","Epoch 333/5000\n","376/376 [==============================] - 42s 111ms/step - loss: 1.1724 - accuracy: 0.6856 - val_loss: 1.4147 - val_accuracy: 0.6517 - lr: 3.1641e-05\n","Epoch 334/5000\n","376/376 [==============================] - 43s 113ms/step - loss: 1.1782 - accuracy: 0.6944 - val_loss: 1.4177 - val_accuracy: 0.6468 - lr: 3.1641e-05\n","Epoch 335/5000\n","376/376 [==============================] - 51s 134ms/step - loss: 1.1716 - accuracy: 0.6911 - val_loss: 1.4180 - val_accuracy: 0.6475 - lr: 3.1641e-05\n","Epoch 336/5000\n","376/376 [==============================] - 41s 109ms/step - loss: 1.1653 - accuracy: 0.6876 - val_loss: 1.4153 - val_accuracy: 0.6496 - lr: 3.1641e-05\n","Epoch 337/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.1481 - accuracy: 0.7004 - val_loss: 1.4154 - val_accuracy: 0.6489 - lr: 3.1641e-05\n","Epoch 338/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.1636 - accuracy: 0.6877 - val_loss: 1.4172 - val_accuracy: 0.6503 - lr: 3.1641e-05\n","Epoch 339/5000\n","376/376 [==============================] - ETA: 0s - loss: 1.1761 - accuracy: 0.6912\n","Epoch 339: ReduceLROnPlateau reducing learning rate to 2.3730469365546014e-05.\n","376/376 [==============================] - 39s 102ms/step - loss: 1.1761 - accuracy: 0.6912 - val_loss: 1.4173 - val_accuracy: 0.6489 - lr: 3.1641e-05\n","Epoch 340/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.1833 - accuracy: 0.6871 - val_loss: 1.4143 - val_accuracy: 0.6482 - lr: 2.3730e-05\n","Epoch 341/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.1741 - accuracy: 0.6894 - val_loss: 1.4150 - val_accuracy: 0.6468 - lr: 2.3730e-05\n","Epoch 342/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.1724 - accuracy: 0.6867 - val_loss: 1.4126 - val_accuracy: 0.6482 - lr: 2.3730e-05\n","Epoch 343/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.1744 - accuracy: 0.6916 - val_loss: 1.4128 - val_accuracy: 0.6510 - lr: 2.3730e-05\n","Epoch 344/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.1714 - accuracy: 0.6849 - val_loss: 1.4124 - val_accuracy: 0.6468 - lr: 2.3730e-05\n","Epoch 345/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.1706 - accuracy: 0.6917 - val_loss: 1.4132 - val_accuracy: 0.6489 - lr: 2.3730e-05\n","Epoch 346/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.1669 - accuracy: 0.6911 - val_loss: 1.4173 - val_accuracy: 0.6496 - lr: 2.3730e-05\n","Epoch 347/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.1624 - accuracy: 0.6941 - val_loss: 1.4171 - val_accuracy: 0.6482 - lr: 2.3730e-05\n","Epoch 348/5000\n","376/376 [==============================] - 45s 118ms/step - loss: 1.1574 - accuracy: 0.6959 - val_loss: 1.4130 - val_accuracy: 0.6517 - lr: 2.3730e-05\n","Epoch 349/5000\n","376/376 [==============================] - 41s 110ms/step - loss: 1.1719 - accuracy: 0.6964 - val_loss: 1.4141 - val_accuracy: 0.6524 - lr: 2.3730e-05\n","Epoch 350/5000\n","376/376 [==============================] - 40s 106ms/step - loss: 1.1597 - accuracy: 0.6917 - val_loss: 1.4120 - val_accuracy: 0.6489 - lr: 2.3730e-05\n","Epoch 351/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.1817 - accuracy: 0.6907 - val_loss: 1.4130 - val_accuracy: 0.6482 - lr: 2.3730e-05\n","Epoch 352/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.1696 - accuracy: 0.6881 - val_loss: 1.4136 - val_accuracy: 0.6475 - lr: 2.3730e-05\n","Epoch 353/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.1669 - accuracy: 0.6876 - val_loss: 1.4136 - val_accuracy: 0.6468 - lr: 2.3730e-05\n","Epoch 354/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.1611 - accuracy: 0.6919 - val_loss: 1.4125 - val_accuracy: 0.6524 - lr: 2.3730e-05\n","Epoch 355/5000\n","376/376 [==============================] - 41s 108ms/step - loss: 1.1669 - accuracy: 0.6951 - val_loss: 1.4172 - val_accuracy: 0.6475 - lr: 2.3730e-05\n","Epoch 356/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.1689 - accuracy: 0.6852 - val_loss: 1.4152 - val_accuracy: 0.6489 - lr: 2.3730e-05\n","Epoch 357/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.1584 - accuracy: 0.6907 - val_loss: 1.4184 - val_accuracy: 0.6482 - lr: 2.3730e-05\n","Epoch 358/5000\n","375/376 [============================>.] - ETA: 0s - loss: 1.1638 - accuracy: 0.6918\n","Epoch 358: ReduceLROnPlateau reducing learning rate to 1.7797852706280537e-05.\n","376/376 [==============================] - 39s 105ms/step - loss: 1.1628 - accuracy: 0.6922 - val_loss: 1.4154 - val_accuracy: 0.6475 - lr: 2.3730e-05\n","Epoch 359/5000\n","376/376 [==============================] - 42s 111ms/step - loss: 1.1811 - accuracy: 0.6889 - val_loss: 1.4142 - val_accuracy: 0.6503 - lr: 1.7798e-05\n","Epoch 360/5000\n","376/376 [==============================] - 41s 108ms/step - loss: 1.1473 - accuracy: 0.6921 - val_loss: 1.4118 - val_accuracy: 0.6503 - lr: 1.7798e-05\n","Epoch 361/5000\n","376/376 [==============================] - 40s 107ms/step - loss: 1.1585 - accuracy: 0.6947 - val_loss: 1.4115 - val_accuracy: 0.6496 - lr: 1.7798e-05\n","Epoch 362/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.1931 - accuracy: 0.6891 - val_loss: 1.4133 - val_accuracy: 0.6482 - lr: 1.7798e-05\n","Epoch 363/5000\n","376/376 [==============================] - 42s 112ms/step - loss: 1.1624 - accuracy: 0.6936 - val_loss: 1.4113 - val_accuracy: 0.6496 - lr: 1.7798e-05\n","Epoch 364/5000\n","376/376 [==============================] - 44s 117ms/step - loss: 1.1876 - accuracy: 0.6831 - val_loss: 1.4125 - val_accuracy: 0.6496 - lr: 1.7798e-05\n","Epoch 365/5000\n","376/376 [==============================] - 44s 117ms/step - loss: 1.1707 - accuracy: 0.6907 - val_loss: 1.4155 - val_accuracy: 0.6461 - lr: 1.7798e-05\n","Epoch 366/5000\n","376/376 [==============================] - 45s 118ms/step - loss: 1.1578 - accuracy: 0.7035 - val_loss: 1.4152 - val_accuracy: 0.6496 - lr: 1.7798e-05\n","Epoch 367/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.1814 - accuracy: 0.6901 - val_loss: 1.4128 - val_accuracy: 0.6489 - lr: 1.7798e-05\n","Epoch 368/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.1685 - accuracy: 0.6906 - val_loss: 1.4169 - val_accuracy: 0.6489 - lr: 1.7798e-05\n","Epoch 369/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.1699 - accuracy: 0.6857 - val_loss: 1.4138 - val_accuracy: 0.6517 - lr: 1.7798e-05\n","Epoch 370/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.1493 - accuracy: 0.6992 - val_loss: 1.4133 - val_accuracy: 0.6517 - lr: 1.7798e-05\n","Epoch 371/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.1604 - accuracy: 0.6959 - val_loss: 1.4106 - val_accuracy: 0.6531 - lr: 1.7798e-05\n","Epoch 372/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.1578 - accuracy: 0.6927 - val_loss: 1.4118 - val_accuracy: 0.6517 - lr: 1.7798e-05\n","Epoch 373/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.1623 - accuracy: 0.6946 - val_loss: 1.4119 - val_accuracy: 0.6475 - lr: 1.7798e-05\n","Epoch 374/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.1812 - accuracy: 0.6932 - val_loss: 1.4131 - val_accuracy: 0.6496 - lr: 1.7798e-05\n","Epoch 375/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.1686 - accuracy: 0.6861 - val_loss: 1.4129 - val_accuracy: 0.6503 - lr: 1.7798e-05\n","Epoch 376/5000\n","376/376 [==============================] - 39s 104ms/step - loss: 1.1587 - accuracy: 0.6906 - val_loss: 1.4136 - val_accuracy: 0.6468 - lr: 1.7798e-05\n","Epoch 377/5000\n","376/376 [==============================] - 39s 102ms/step - loss: 1.1726 - accuracy: 0.6936 - val_loss: 1.4138 - val_accuracy: 0.6454 - lr: 1.7798e-05\n","Epoch 378/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.1795 - accuracy: 0.6837 - val_loss: 1.4096 - val_accuracy: 0.6482 - lr: 1.7798e-05\n","Epoch 379/5000\n","376/376 [==============================] - 39s 103ms/step - loss: 1.1609 - accuracy: 0.6907 - val_loss: 1.4097 - val_accuracy: 0.6489 - lr: 1.7798e-05\n","Epoch 380/5000\n","376/376 [==============================] - 40s 105ms/step - loss: 1.1771 - accuracy: 0.6872 - val_loss: 1.4092 - val_accuracy: 0.6503 - lr: 1.7798e-05\n","Epoch 381/5000\n","376/376 [==============================] - 44s 115ms/step - loss: 1.1562 - accuracy: 0.6966 - val_loss: 1.4110 - val_accuracy: 0.6482 - lr: 1.7798e-05\n","Epoch 382/5000\n","376/376 [==============================] - 47s 126ms/step - loss: 1.1523 - accuracy: 0.6957 - val_loss: 1.4110 - val_accuracy: 0.6482 - lr: 1.7798e-05\n","Epoch 383/5000\n","376/376 [==============================] - 44s 117ms/step - loss: 1.1626 - accuracy: 0.6946 - val_loss: 1.4114 - val_accuracy: 0.6482 - lr: 1.7798e-05\n","Epoch 384/5000\n","376/376 [==============================] - 43s 115ms/step - loss: 1.1753 - accuracy: 0.6864 - val_loss: 1.4094 - val_accuracy: 0.6496 - lr: 1.7798e-05\n","Epoch 385/5000\n","376/376 [==============================] - 44s 115ms/step - loss: 1.1581 - accuracy: 0.6879 - val_loss: 1.4131 - val_accuracy: 0.6440 - lr: 1.7798e-05\n","Epoch 386/5000\n","376/376 [==============================] - 43s 115ms/step - loss: 1.1507 - accuracy: 0.6877 - val_loss: 1.4095 - val_accuracy: 0.6489 - lr: 1.7798e-05\n","Epoch 387/5000\n","376/376 [==============================] - 43s 115ms/step - loss: 1.1555 - accuracy: 0.6949 - val_loss: 1.4110 - val_accuracy: 0.6454 - lr: 1.7798e-05\n","Epoch 388/5000\n","375/376 [============================>.] - ETA: 0s - loss: 1.1642 - accuracy: 0.6922\n","Epoch 388: ReduceLROnPlateau reducing learning rate to 1.3348389529710403e-05.\n","376/376 [==============================] - 43s 115ms/step - loss: 1.1638 - accuracy: 0.6922 - val_loss: 1.4108 - val_accuracy: 0.6489 - lr: 1.7798e-05\n","Epoch 389/5000\n","376/376 [==============================] - 45s 118ms/step - loss: 1.1636 - accuracy: 0.6916 - val_loss: 1.4103 - val_accuracy: 0.6482 - lr: 1.3348e-05\n","Epoch 390/5000\n","376/376 [==============================] - 44s 115ms/step - loss: 1.1507 - accuracy: 0.6911 - val_loss: 1.4104 - val_accuracy: 0.6503 - lr: 1.3348e-05\n","Epoch 391/5000\n","376/376 [==============================] - 44s 116ms/step - loss: 1.1663 - accuracy: 0.6921 - val_loss: 1.4077 - val_accuracy: 0.6503 - lr: 1.3348e-05\n","Epoch 392/5000\n","376/376 [==============================] - 43s 115ms/step - loss: 1.1650 - accuracy: 0.6974 - val_loss: 1.4094 - val_accuracy: 0.6503 - lr: 1.3348e-05\n","Epoch 393/5000\n","376/376 [==============================] - 43s 115ms/step - loss: 1.1812 - accuracy: 0.6847 - val_loss: 1.4103 - val_accuracy: 0.6475 - lr: 1.3348e-05\n","Epoch 394/5000\n","376/376 [==============================] - 44s 115ms/step - loss: 1.1576 - accuracy: 0.6956 - val_loss: 1.4098 - val_accuracy: 0.6496 - lr: 1.3348e-05\n","Epoch 395/5000\n","376/376 [==============================] - 43s 115ms/step - loss: 1.1602 - accuracy: 0.6854 - val_loss: 1.4112 - val_accuracy: 0.6496 - lr: 1.3348e-05\n","Epoch 396/5000\n","376/376 [==============================] - 45s 118ms/step - loss: 1.1598 - accuracy: 0.6946 - val_loss: 1.4118 - val_accuracy: 0.6489 - lr: 1.3348e-05\n","Epoch 397/5000\n","376/376 [==============================] - 44s 115ms/step - loss: 1.1521 - accuracy: 0.7007 - val_loss: 1.4123 - val_accuracy: 0.6489 - lr: 1.3348e-05\n","Epoch 398/5000\n","376/376 [==============================] - 43s 115ms/step - loss: 1.1715 - accuracy: 0.6864 - val_loss: 1.4104 - val_accuracy: 0.6475 - lr: 1.3348e-05\n","Epoch 399/5000\n","375/376 [============================>.] - ETA: 0s - loss: 1.1671 - accuracy: 0.6928\n","Epoch 399: ReduceLROnPlateau reducing learning rate to 1.0011292488343315e-05.\n","376/376 [==============================] - 43s 115ms/step - loss: 1.1675 - accuracy: 0.6926 - val_loss: 1.4084 - val_accuracy: 0.6496 - lr: 1.3348e-05\n","Epoch 400/5000\n","376/376 [==============================] - 43s 115ms/step - loss: 1.1700 - accuracy: 0.6927 - val_loss: 1.4105 - val_accuracy: 0.6489 - lr: 1.0011e-05\n","Epoch 401/5000\n","376/376 [==============================] - 43s 115ms/step - loss: 1.1630 - accuracy: 0.6929 - val_loss: 1.4095 - val_accuracy: 0.6489 - lr: 1.0011e-05\n","Epoch 402/5000\n","376/376 [==============================] - 44s 115ms/step - loss: 1.1461 - accuracy: 0.6974 - val_loss: 1.4117 - val_accuracy: 0.6496 - lr: 1.0011e-05\n","Epoch 403/5000\n","376/376 [==============================] - 43s 114ms/step - loss: 1.1619 - accuracy: 0.6922 - val_loss: 1.4115 - val_accuracy: 0.6489 - lr: 1.0011e-05\n","Epoch 404/5000\n","376/376 [==============================] - 43s 115ms/step - loss: 1.1654 - accuracy: 0.6911 - val_loss: 1.4106 - val_accuracy: 0.6489 - lr: 1.0011e-05\n","Epoch 405/5000\n","376/376 [==============================] - 44s 116ms/step - loss: 1.1544 - accuracy: 0.6964 - val_loss: 1.4105 - val_accuracy: 0.6482 - lr: 1.0011e-05\n","Epoch 406/5000\n","376/376 [==============================] - 44s 116ms/step - loss: 1.1745 - accuracy: 0.6931 - val_loss: 1.4096 - val_accuracy: 0.6510 - lr: 1.0011e-05\n","Epoch 407/5000\n","375/376 [============================>.] - ETA: 0s - loss: 1.1643 - accuracy: 0.6918\n","Epoch 407: ReduceLROnPlateau reducing learning rate to 7.508469025196973e-06.\n","376/376 [==============================] - 44s 117ms/step - loss: 1.1637 - accuracy: 0.6917 - val_loss: 1.4113 - val_accuracy: 0.6510 - lr: 1.0011e-05\n","Model Training Time: 24978.317909002304 seconds\n","Model Training Time: 416.31 minutes\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: models/MobileNetV2/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: models/MobileNetV2/assets\n"]}],"source":["train_model()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":0}
