{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "549d6812-b9ec-420b-a7a4-792e1c2b291e",
   "metadata": {},
   "source": [
    "## Audio Weather Classification Script\n",
    "\n",
    "This script is designed to perform audio classification using convolutional neural networks (CNNs). It loads audio files from the specified directory, preprocesses them by converting them to mel spectrograms, pads them to ensure uniform dimensions, and then trains a CNN model for classifying the audio into different classes.\n",
    "\n",
    "### Steps:\n",
    "1. **Data Loading and Preprocessing**: Audio files are loaded from the specified directory (`path`) and converted to mel spectrograms using the Librosa library. The spectrograms are then padded to ensure uniform dimensions.\n",
    "\n",
    "2. **Data Splitting**: The preprocessed data is split into training and testing sets using a specified test size.\n",
    "\n",
    "3. **Model Architecture**: The CNN model architecture consists of two convolutional layers followed by max-pooling layers and dropout regularization. The output is passed through fully connected layers with ReLU activation functions, and a softmax activation function is used for multi-class classification.\n",
    "\n",
    "4. **Training**: The model is trained using the training data, and the training progress is monitored using accuracy and loss metrics.\n",
    "\n",
    "### Libraries Used:\n",
    "- Librosa: For audio processing\n",
    "- NumPy: For numerical operations\n",
    "- TensorFlow and Keras: For building and training the CNN model\n",
    "- Scikit-learn: For data preprocessing and splitting\n",
    "\n",
    "Feel free to modify the script and experiment with different parameters to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e9811d-822d-430e-af43-647ac12f7478",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ee421b-0b4f-4a63-b53b-86163a866b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "#import librosa.display\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6925d654-1609-4d87-ac0a-9f8e8bb4921c",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a4e4a18-c07f-48f8-b92f-ac066bef64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a class to contain the data storage loading and spectogram creation \n",
    "# this is done in order to simpllfy the handling of data and vriables in dealing with multiple threads with out\n",
    "# having to use multiple segements haded to each call of the function \n",
    "\n",
    "\n",
    "class WeatherData:\n",
    "\n",
    "    # number of parallel jobs to run\n",
    "    n_jobs = 12\n",
    "    # alters level of feed back from parallel workers \n",
    "    verbose = 5\n",
    "    target_length=216\n",
    "    # class labels \n",
    "    class_labels =  [\"Rain\", \"Thunder\"] # Class names (\"Rain\", \"Thunder\", \"Earthquake\", \"Flood\" , \"Tornado\", \"Volcano\")\n",
    "    # change to suit where the data is stored \n",
    "    path = r'D:\\Weather_Sounds\\Weather_sounds'\n",
    "\n",
    "    audios = []\n",
    "    labels = []\n",
    "    mel_spectrograms = []\n",
    "    audio_to_process= []\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# defualt initilisation function for the class \n",
    "    def __init__(_path = r'D:\\Weather_Sounds\\Weather_sounds', _n_jobs =8, _class_labels = [\"Rain\", \"Thunder\"],_target_length=216  ):\n",
    "        path = _path\n",
    "        n_jobs=_n_jobs\n",
    "        class_labels = _class_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def load_and_pad_audio(self,file_path):\n",
    "        # Load audio file\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Calculate the number of required samples\n",
    "        required_samples = int(self.target_length * sr / 10.0)\n",
    "\n",
    "        if len(audio) < required_samples:\n",
    "            # Pad audio if it is too short\n",
    "            audio = np.pad(audio, (0, max(0, required_samples - len(audio))), \"constant\")\n",
    "        else:\n",
    "            # Truncate audio if it is too long\n",
    "            audio = audio[:required_samples]\n",
    "        \n",
    "        return audio, sr\n",
    "\n",
    "    def load_audio_files(self):\n",
    "        i = 0\n",
    "        files_to_load = []\n",
    "        length =0\n",
    "\n",
    "    # iterate through lables \n",
    "        for label in self.class_labels:\n",
    "            # create label class path\n",
    "            class_path =(os.path.join(self.path, label))\n",
    "            # here we are creatinga length property for the list that will hold the samples and the the rate as the parrallel\n",
    "            #function wil need to have have all data toiterate before starting and need to pre set the list length so as to have relevent data \n",
    "            # stored in the appropraite index  rather than relying on the order as differnet threads may finish at differnet times reltive to their start   \n",
    "            length += len(os.listdir(class_path))\n",
    "            files_to_load.append(os.listdir(class_path))\n",
    "        self.audio_to_process = [[] for i in range(length)]\n",
    "        self.mel_spectrograms = [None]*length\n",
    "        \n",
    "        for label in self.class_labels:\n",
    "            # Path to the folder containing audio files of a specific label\n",
    "            class_path = os.path.join(self.path, label)\n",
    "            audio = None\n",
    "\n",
    "            # load data to the lists \n",
    "            for file in os.listdir(class_path):\n",
    "                file_path = os.path.join(class_path, file)\n",
    "                audio, sr = self.load_and_pad_audio(file_path)\n",
    "                self.audio_to_process[i].append(audio)\n",
    "                self.audio_to_process[i].append(sr)\n",
    "                self.audio_to_process[i].append(i)\n",
    "                self.labels.append(label)\n",
    "                \n",
    "                i+=1\n",
    "\n",
    "            print(len(self.audio_to_process))\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function for creating the specogram usaing the index of the passed list item \n",
    "    def create_spectrogram(self,audio):\n",
    "        \n",
    "        output = librosa.feature.melspectrogram(y=audio[0], sr=audio[1], n_mels=128)\n",
    "\n",
    "        return output\n",
    "        \n",
    "        \n",
    "# parallel function using the \n",
    "    def parallel_Spectogram(self):\n",
    "            # joblib libarary allows  for the allocation of worker threads to carry out the spectogram creation based on the for loop of the range of data samples \n",
    "            output = joblib.Parallel(n_jobs=self.n_jobs,verbose=self.verbose,prefer=\"threads\")(joblib.delayed(self.create_spectrogram)(self.audio_to_process[i]) for i in range(len(self.audio_to_process)))\n",
    "                \n",
    "            for mel_spectrogram in output:\n",
    "                log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
    "                self.audios.append(log_mel_spectrogram)\n",
    "\n",
    "            \n",
    "# functioin to plot the spectograms \n",
    "    def plot_mel_spectrogram_full(self,mel_spectrogram):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "        plt.title(\"Log Mel Spectrogram of Audio\")    \n",
    "        img = librosa.display.specshow(librosa.power_to_db(mel_spectrogram, ref=np.max),\n",
    "                                    x_axis='time',  y_axis='mel', hop_length = 128, fmax=8000)\n",
    "        fig.colorbar(img, ax=ax, format=f'%0.2f dB')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88474398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4294\n",
      "7895\n",
      "7895\n",
      "7895\n"
     ]
    }
   ],
   "source": [
    "# create weather data instance \n",
    "weatherData =  WeatherData()\n",
    "weatherData.__init__()\n",
    "# call the load function \n",
    "weatherData.load_audio_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028abef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=12)]: Done 624 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=12)]: Done 858 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=12)]: Done 1128 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=12)]: Done 1434 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=12)]: Done 2154 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=12)]: Done 2568 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=12)]: Done 3018 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=12)]: Done 3504 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=12)]: Done 4026 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=12)]: Done 4584 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=12)]: Done 5178 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=12)]: Done 5808 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=12)]: Done 6474 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=12)]: Done 7176 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=12)]: Done 7895 out of 7895 | elapsed:  6.7min finished\n"
     ]
    }
   ],
   "source": [
    "# create the spectograms \n",
    "weatherData.parallel_Spectogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "928cc8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "audios = weatherData.audios\n",
    "labels = weatherData.labels\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)\n",
    "\n",
    "# Finding max dimensions for padding\n",
    "max_length = max(audio.shape[1] for audio in audios)\n",
    "max_height = max(audio.shape[0] for audio in audios)\n",
    "\n",
    "# Pad spectrograms to the max dimensions\n",
    "audios_padded = np.array([np.pad(audio, ((0, max_height - audio.shape[0]), (0, max_length - audio.shape[1])), 'constant') for audio in audios])\n",
    "\n",
    "# Reshape for CNN input\n",
    "audios_array = audios_padded.reshape(audios_padded.shape[0], audios_padded.shape[1], audios_padded.shape[2], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "568efd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7895, 128, 1861, 1)\n",
      "(7895, 2)\n",
      "7895\n",
      "7895\n",
      "7895\n"
     ]
    }
   ],
   "source": [
    "print(audios_array.shape)\n",
    "print(labels_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b99a1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(audios_array, labels_categorical, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb230e-a7af-47fd-a755-b074e6018020",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "642f15a6-7097-46e9-8b18-4a4e3710fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First conv block\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # Second conv block\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # Flatten and Dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0414dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# This call is for the TF distrubute library that allows for mirroring of task on multiple systems in this case accross multipple GPU's \n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# allow for running of the the mosel tranning under the chosen  stratergy \n",
    "with strategy.scope():\n",
    "    model = build_model(input_shape=(X_train.shape[1], X_train.shape[2], 1), num_classes=len(weatherData.class_labels))\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=1)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(history.history['loss'], label='Training loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f80754-d71e-4fd9-a446-f038285480a4",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32520083-9891-4d9b-a556-d261005f83e7",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565826cd-2a23-44dd-9ba8-e3f7d44816b9",
   "metadata": {},
   "source": [
    "#### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e51748-77d9-482d-b89d-c8b827c7bd79",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Echo (Python 3.10.13)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n Echo ipykernel --update-deps --force-reinstall'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define the path to save the model PB format\n",
    "model_dir = \"weather_audio_detection_model\"\n",
    "\n",
    "# Save the model in SavedModel format\n",
    "tf.saved_model.save(model, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95142574-501a-4383-b4e1-3a899bfb4cfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Echo (Python 3.10.13)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n Echo ipykernel --update-deps --force-reinstall'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Save model in h5 format\n",
    "model.save('WeatherAudioDetectionModel.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
