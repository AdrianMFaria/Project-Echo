{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# basic imports\n",
    "import tensorflow as tf \n",
    "import torch\n",
    "import io\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.utils import dataset_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import baseline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12384 files belonging to 5 classes.\n",
      "Found 487 files belonging to 5 classes.\n",
      "Found 384 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "def paths_and_labels_to_dataset(image_paths,labels,num_classes):\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    img_ds = path_ds.map(\n",
    "        lambda path: tf.io.read_file(path) , num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    label_ds = dataset_utils.labels_to_dataset(labels, True, num_classes)\n",
    "    img_ds = tf.data.Dataset.zip((img_ds, label_ds))\n",
    "    return img_ds\n",
    "\n",
    "def create_dataset(subset):\n",
    "    image_paths, labels, class_names = dataset_utils.index_directory(\n",
    "            baseline_config.dataset_path + subset,\n",
    "            labels=\"inferred\",\n",
    "            formats=('.pt'),\n",
    "            class_names=None,\n",
    "            shuffle=False,\n",
    "            seed=42,\n",
    "            follow_links=True)\n",
    "\n",
    "    dataset = paths_and_labels_to_dataset(\n",
    "        image_paths=image_paths,\n",
    "        labels=labels,\n",
    "        num_classes=len(class_names))\n",
    "    \n",
    "    return dataset, class_names\n",
    "\n",
    "train_dataset, class_names = create_dataset('TRAIN/')\n",
    "test_dataset,_             = create_dataset('TEST/')\n",
    "validation_dataset,_       = create_dataset('VALIDATION/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_tranforms(image,label):\n",
    "    image = torch.load(io.BytesIO(image.numpy()))\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.repeat(image, 3, 2)\n",
    "    label = tf.cast(label, tf.int64)\n",
    "    return image,label\n",
    "\n",
    "py_func_wrapper = lambda x,y: tf.py_function(func=dataset_tranforms, inp=[x,y], Tout=[tf.float32,tf.int64])\n",
    "\n",
    "train_dataset = ( \n",
    "                  train_dataset\n",
    "                  .shuffle(20000)\n",
    "                  .map(py_func_wrapper)\n",
    "                  .repeat()\n",
    "                  .batch(baseline_config.batch_size)       \n",
    "                )\n",
    "\n",
    "validation_dataset = ( \n",
    "                  validation_dataset\n",
    "                  .shuffle(20000)\n",
    "                  .map(py_func_wrapper)\n",
    "                  .batch(baseline_config.batch_size)\n",
    "                )\n",
    "\n",
    "test_dataset = ( \n",
    "                  test_dataset\n",
    "                  .shuffle(20000)\n",
    "                  .map(py_func_wrapper)\n",
    "                  .batch(baseline_config.batch_size)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing (Resizing)         (None, 384, 384, 3)       0         \n",
      "                                                                 \n",
      " keras_layer (KerasLayer)    (None, 1280)              20331360  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               327936    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,660,581\n",
      "Trainable params: 329,221\n",
      "Non-trainable params: 20,331,360\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a really simple classification model using a pre-training Efficientnet V2\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        # use the model as a feature generator only\n",
    "        # need to resize here, as the efficientnet_v2_imagenet1k_b3 model requires 260x260 input\n",
    "        #tf.keras.layers.Resizing(260, 260, interpolation=\"bilinear\", crop_to_aspect_ratio=False),\n",
    "        #hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b3/feature_vector/2\", False),\n",
    "        \n",
    "        # use the model as a feature generator only\n",
    "        # need to resize here, as the efficientnet_v2_imagenet21k_s model expects it\n",
    "        tf.keras.layers.Resizing(384, 384, interpolation=\"bilinear\", crop_to_aspect_ratio=False),\n",
    "        hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_s/feature_vector/2\", False),        \n",
    "\n",
    "        # add the classification layer here       \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dropout(0.70),\n",
    "        layers.Dense(len(class_names), activation=None),\n",
    "    ]\n",
    ")\n",
    "# need to tell the model what the input shape is\n",
    "model.build([None, 313, 128, 3])\n",
    "\n",
    "# show the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 5.0631 - accuracy: 0.2587\n",
      "Epoch 1: val_loss improved from inf to 3.03321, saving model to checkpoints\\\n",
      "50/50 [==============================] - 42s 542ms/step - loss: 5.0631 - accuracy: 0.2587 - val_loss: 3.0332 - val_accuracy: 0.4062\n",
      "Epoch 2/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 3.2849 - accuracy: 0.2937\n",
      "Epoch 2: val_loss improved from 3.03321 to 2.95877, saving model to checkpoints\\\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 3.2849 - accuracy: 0.2937 - val_loss: 2.9588 - val_accuracy: 0.4401\n",
      "Epoch 3/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 3.6408 - accuracy: 0.3100\n",
      "Epoch 3: val_loss improved from 2.95877 to 2.54228, saving model to checkpoints\\\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 3.6408 - accuracy: 0.3100 - val_loss: 2.5423 - val_accuracy: 0.4401\n",
      "Epoch 4/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 2.9968 - accuracy: 0.3200\n",
      "Epoch 4: val_loss improved from 2.54228 to 2.35145, saving model to checkpoints\\\n",
      "50/50 [==============================] - 26s 532ms/step - loss: 2.9968 - accuracy: 0.3200 - val_loss: 2.3515 - val_accuracy: 0.4635\n",
      "Epoch 5/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 2.5404 - accuracy: 0.3812\n",
      "Epoch 5: val_loss did not improve from 2.35145\n",
      "50/50 [==============================] - 25s 504ms/step - loss: 2.5404 - accuracy: 0.3812 - val_loss: 2.3881 - val_accuracy: 0.4896\n",
      "Epoch 6/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 2.1768 - accuracy: 0.3762\n",
      "Epoch 6: val_loss improved from 2.35145 to 2.16448, saving model to checkpoints\\\n",
      "50/50 [==============================] - 27s 534ms/step - loss: 2.1768 - accuracy: 0.3762 - val_loss: 2.1645 - val_accuracy: 0.4792\n",
      "Epoch 7/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.9632 - accuracy: 0.4125\n",
      "Epoch 7: val_loss improved from 2.16448 to 2.08055, saving model to checkpoints\\\n",
      "50/50 [==============================] - 27s 538ms/step - loss: 1.9632 - accuracy: 0.4125 - val_loss: 2.0806 - val_accuracy: 0.4818\n",
      "Epoch 8/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 2.3405 - accuracy: 0.4050\n",
      "Epoch 8: val_loss improved from 2.08055 to 2.05515, saving model to checkpoints\\\n",
      "50/50 [==============================] - 27s 533ms/step - loss: 2.3405 - accuracy: 0.4050 - val_loss: 2.0551 - val_accuracy: 0.4714\n",
      "Epoch 9/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.6435 - accuracy: 0.4187\n",
      "Epoch 9: val_loss did not improve from 2.05515\n",
      "50/50 [==============================] - 25s 506ms/step - loss: 1.6435 - accuracy: 0.4187 - val_loss: 2.1645 - val_accuracy: 0.4896\n",
      "Epoch 10/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.8143 - accuracy: 0.4275\n",
      "Epoch 10: val_loss did not improve from 2.05515\n",
      "50/50 [==============================] - 25s 504ms/step - loss: 1.8143 - accuracy: 0.4275 - val_loss: 2.1097 - val_accuracy: 0.4974\n",
      "Epoch 11/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.8570 - accuracy: 0.4363\n",
      "Epoch 11: val_loss did not improve from 2.05515\n",
      "50/50 [==============================] - 25s 498ms/step - loss: 1.8570 - accuracy: 0.4363 - val_loss: 2.0663 - val_accuracy: 0.5286\n",
      "Epoch 12/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.9729 - accuracy: 0.4300\n",
      "Epoch 12: val_loss did not improve from 2.05515\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 1.9729 - accuracy: 0.4300 - val_loss: 2.1435 - val_accuracy: 0.5234\n",
      "Epoch 13/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.7416 - accuracy: 0.4600\n",
      "Epoch 13: val_loss did not improve from 2.05515\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 1.7416 - accuracy: 0.4600 - val_loss: 2.1937 - val_accuracy: 0.5182\n",
      "Epoch 14/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 2.2220 - accuracy: 0.4712\n",
      "Epoch 14: val_loss improved from 2.05515 to 2.05237, saving model to checkpoints\\\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 2.2220 - accuracy: 0.4712 - val_loss: 2.0524 - val_accuracy: 0.5078\n",
      "Epoch 15/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.7826 - accuracy: 0.4613\n",
      "Epoch 15: val_loss did not improve from 2.05237\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 1.7826 - accuracy: 0.4613 - val_loss: 2.0573 - val_accuracy: 0.5312\n",
      "Epoch 16/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.6282 - accuracy: 0.4575\n",
      "Epoch 16: val_loss did not improve from 2.05237\n",
      "50/50 [==============================] - 27s 539ms/step - loss: 1.6282 - accuracy: 0.4575 - val_loss: 2.1347 - val_accuracy: 0.4922\n",
      "Epoch 17/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.5547 - accuracy: 0.4913\n",
      "Epoch 17: val_loss improved from 2.05237 to 1.96457, saving model to checkpoints\\\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 1.5547 - accuracy: 0.4913 - val_loss: 1.9646 - val_accuracy: 0.5182\n",
      "Epoch 18/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.4800 - accuracy: 0.4787\n",
      "Epoch 18: val_loss did not improve from 1.96457\n",
      "50/50 [==============================] - 25s 505ms/step - loss: 1.4800 - accuracy: 0.4787 - val_loss: 2.0288 - val_accuracy: 0.5547\n",
      "Epoch 19/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.5121 - accuracy: 0.4863\n",
      "Epoch 19: val_loss improved from 1.96457 to 1.95048, saving model to checkpoints\\\n",
      "50/50 [==============================] - 27s 533ms/step - loss: 1.5121 - accuracy: 0.4863 - val_loss: 1.9505 - val_accuracy: 0.5130\n",
      "Epoch 20/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.3210 - accuracy: 0.5125\n",
      "Epoch 20: val_loss did not improve from 1.95048\n",
      "50/50 [==============================] - 25s 509ms/step - loss: 1.3210 - accuracy: 0.5125 - val_loss: 1.9627 - val_accuracy: 0.5156\n",
      "Epoch 21/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.4420 - accuracy: 0.4762\n",
      "Epoch 21: val_loss did not improve from 1.95048\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 1.4420 - accuracy: 0.4762 - val_loss: 1.9960 - val_accuracy: 0.5208\n",
      "Epoch 22/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.3406 - accuracy: 0.5275\n",
      "Epoch 22: val_loss improved from 1.95048 to 1.91142, saving model to checkpoints\\\n",
      "50/50 [==============================] - 27s 536ms/step - loss: 1.3406 - accuracy: 0.5275 - val_loss: 1.9114 - val_accuracy: 0.5391\n",
      "Epoch 23/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.6202 - accuracy: 0.5025\n",
      "Epoch 23: val_loss did not improve from 1.91142\n",
      "50/50 [==============================] - 25s 510ms/step - loss: 1.6202 - accuracy: 0.5025 - val_loss: 1.9935 - val_accuracy: 0.5391\n",
      "Epoch 24/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.9664 - accuracy: 0.5100\n",
      "Epoch 24: val_loss did not improve from 1.91142\n",
      "50/50 [==============================] - 25s 506ms/step - loss: 1.9664 - accuracy: 0.5100 - val_loss: 1.9557 - val_accuracy: 0.5469\n",
      "Epoch 25/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.5067 - accuracy: 0.5337\n",
      "Epoch 25: val_loss did not improve from 1.91142\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 1.5067 - accuracy: 0.5337 - val_loss: 1.9576 - val_accuracy: 0.5521\n",
      "Epoch 26/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.2184 - accuracy: 0.5487\n",
      "Epoch 26: val_loss improved from 1.91142 to 1.84898, saving model to checkpoints\\\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 1.2184 - accuracy: 0.5487 - val_loss: 1.8490 - val_accuracy: 0.5573\n",
      "Epoch 27/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.2973 - accuracy: 0.5550\n",
      "Epoch 27: val_loss did not improve from 1.84898\n",
      "50/50 [==============================] - 25s 500ms/step - loss: 1.2973 - accuracy: 0.5550 - val_loss: 1.9358 - val_accuracy: 0.5573\n",
      "Epoch 28/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.2247 - accuracy: 0.5725\n",
      "Epoch 28: val_loss did not improve from 1.84898\n",
      "50/50 [==============================] - 25s 500ms/step - loss: 1.2247 - accuracy: 0.5725 - val_loss: 1.9645 - val_accuracy: 0.5495\n",
      "Epoch 29/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.3721 - accuracy: 0.5387\n",
      "Epoch 29: val_loss did not improve from 1.84898\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 1.3721 - accuracy: 0.5387 - val_loss: 2.0047 - val_accuracy: 0.5104\n",
      "Epoch 30/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.5354 - accuracy: 0.5250\n",
      "Epoch 30: val_loss did not improve from 1.84898\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 1.5354 - accuracy: 0.5250 - val_loss: 2.0001 - val_accuracy: 0.5599\n",
      "Epoch 31/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.3206 - accuracy: 0.5375\n",
      "Epoch 31: val_loss did not improve from 1.84898\n",
      "50/50 [==============================] - 27s 537ms/step - loss: 1.3206 - accuracy: 0.5375 - val_loss: 2.0266 - val_accuracy: 0.5859\n",
      "Epoch 32/100000\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.3615 - accuracy: 0.5575"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 80 values, but the requested shape has 1 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 16\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), \n\u001b[0;32m      4\u001b[0m               optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mbaseline_config\u001b[39m.\u001b[39mlearning_rate, clipnorm\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m), \n\u001b[0;32m      5\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m      6\u001b[0m               run_eagerly\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m model_checkpoint_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\n\u001b[0;32m      9\u001b[0m     filepath\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcheckpoints/\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     save_weights_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     14\u001b[0m     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 16\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_dataset, \n\u001b[0;32m     17\u001b[0m           validation_data\u001b[39m=\u001b[39;49mvalidation_dataset,\n\u001b[0;32m     18\u001b[0m           steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m     19\u001b[0m           callbacks\u001b[39m=\u001b[39;49m[model_checkpoint_callback],\n\u001b[0;32m     20\u001b[0m           epochs\u001b[39m=\u001b[39;49mbaseline_config\u001b[39m.\u001b[39;49mmax_epoch)\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\miniconda3\\envs\\dev\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\miniconda3\\envs\\dev\\lib\\site-packages\\keras\\backend.py:5621\u001b[0m, in \u001b[0;36msparse_categorical_crossentropy\u001b[1;34m(target, output, from_logits, axis, ignore_class)\u001b[0m\n\u001b[0;32m   5619\u001b[0m \u001b[39mif\u001b[39;00m update_shape:\n\u001b[0;32m   5620\u001b[0m     target \u001b[39m=\u001b[39m flatten(target)\n\u001b[1;32m-> 5621\u001b[0m     output \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mreshape(output, [\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, output_shape[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]])\n\u001b[0;32m   5623\u001b[0m \u001b[39mif\u001b[39;00m ignore_class \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5624\u001b[0m     valid_mask \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnot_equal(target, cast(ignore_class, target\u001b[39m.\u001b[39mdtype))\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 80 values, but the requested shape has 1 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "# the form_logits means the loss function has the 'softmax' buillt in.  This approach is numerically more stable\n",
    "# than including the softmax activation on the last layer of the classifier\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=baseline_config.learning_rate), \n",
    "              metrics=[\"accuracy\"], \n",
    "              run_eagerly=True)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='checkpoints/',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "\n",
    "model.fit(train_dataset, \n",
    "          validation_data=validation_dataset,\n",
    "          steps_per_epoch=50,\n",
    "          callbacks=[model_checkpoint_callback],\n",
    "          epochs=baseline_config.max_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2848388c1d7df64c5912f8c74b12cb2f63a5fbb869f66edadd9f1eda580b6df3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
