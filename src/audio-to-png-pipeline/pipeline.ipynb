{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "\n",
    "Author: stephankokkas\n",
    "\n",
    "This notebook defines a pipeline that tasks an input directory of audio files and converts them to images using mel-spectrogram transofrmation and preprocessing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable warnings to tidy up output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# some basic libraries \n",
    "from platform import python_version\n",
    "#import pandas as pd\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "# plot support\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tensorflow support\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow.contrib.framework.python.ops import audio_ops\n",
    "\n",
    "# scipy\n",
    "import scipy\n",
    "\n",
    "# reading audio datasets\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# turn off tensorflow warnings\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# turn off absl warnings\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "# print system information\n",
    "print('Python Version     : ', python_version())\n",
    "print('TensorFlow Version : ', tf.__version__)\n",
    "print('Librosa Version    : ', librosa.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below code adapted from:\n",
    "# https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(123)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "random.seed(123)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set system parameters\n",
    "DATASET_PATH  = 'C:/Users/Andrew/OneDrive - Deakin University/DataSets/birdclef2022/'\n",
    "FILE_FORMAT = ''\n",
    "\n",
    "SAMPLE_RATE   = 32000   # all the samples are converted to bit rate of 32000 (Samples/Second)\n",
    "MIN_FREQUENCY = 16      # minimum frequency (Hz) for the Fast Fourier Transform related functions\n",
    "MAX_FREQUENCY = 4096*3  # minimum frequency (Hz) for the Fast Fourier Transform related functions\n",
    "HOP_LENGTH    = 128     # the number of samples to slide spectrogram window along the audio samples\n",
    "NUMBER_FFT    = 2048    # the number of FFT to execute within a single spectrogram window\n",
    "NUMBER_MELS   = 128     # the number of Mel-Spectrogram groups to split the frequency dimension\n",
    "CLIP_LENGTH   = 5      # only look at 10 seconds of clip at the start of loaded audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
