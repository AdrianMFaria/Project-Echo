{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "\n",
    "Author: stephankokkas\n",
    "\n",
    "This notebook defines a pipeline that tasks an input directory of audio files and converts them to images using mel-spectrogram transofrmation and preprocessing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version     :  3.10.0\n",
      "TensorFlow Version :  2.11.0\n"
     ]
    }
   ],
   "source": [
    "# disable warnings to tidy up output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# some basic libraries \n",
    "from platform import python_version\n",
    "#import pandas as pd\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import torch\n",
    "\n",
    "\n",
    "# plot support\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tensorflow support\n",
    "import tensorflow as tf\n",
    "#import tensorflow_transform as tft\n",
    "import tensorflow_io as tfio\n",
    "#from tensorflow.contrib.framework.python.ops import audio_ops\n",
    "\n",
    "# scipy\n",
    "import scipy\n",
    "from pydub import AudioSegment, effects\n",
    "\n",
    "# turn off tensorflow warnings\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# turn off absl warnings\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "# print system information\n",
    "print('Python Version     : ', python_version())\n",
    "print('TensorFlow Version : ', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below code adapted from:\n",
    "# https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(123)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "random.seed(123)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set system parameters\n",
    "DATASET_PATH  = '/Users/stephankokkas/Downloads/birdclef2022/'\n",
    "\n",
    "SAMPLE_RATE   = 32000   # all the samples are converted to bit rate of 32000 (Samples/Second)\n",
    "MIN_FREQUENCY = 16      # minimum frequency (Hz) for the Fast Fourier Transform related functions\n",
    "MAX_FREQUENCY = 4096*3  # minimum frequency (Hz) for the Fast Fourier Transform related functions\n",
    "HOP_LENGTH    = 128     # the number of samples to slide spectrogram window along the audio samples\n",
    "NUMBER_FFT    = 2048    # the number of FFT to execute within a single spectrogram window\n",
    "NUMBER_MELS   = 128     # the number of Mel-Spectrogram groups to split the frequency dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class raw_file_pre_processing():\n",
    "    def __init__(self) -> None:\n",
    "        self.CLIP_LENGTH   = 5000   # only look at 5000 milliseconds of clip at the start of loaded audio file\n",
    "        self.BITRATE = \"32k\"        # all the samples are converted to bit rate of 32000 (Samples/Second)\n",
    "        self.labels = []\n",
    "        self.raw_dirs = {}\n",
    "        self.mp3_dirs = {}\n",
    "        self.TARGET_FORMAT = 'mp3'\n",
    "        self.ACCEPTED_FORMAT = ['.mp3', '.flac', '.aiff', '.mp4', '.m4a', '.wav', '.ogg']\n",
    "        self.OUTPUT_DIR = os.path.join(DATASET_PATH, 'output')\n",
    "            \n",
    "\n",
    "    def get_raw_file_paths(self, directory):\n",
    "        print(f'Looking for files... acceptable formats include: {self.ACCEPTED_FORMAT}')\n",
    "        for root, dir, files in os.walk(directory):\n",
    "            if dir == [] and \"output\" not in str(root).split(\"/\")[1]:\n",
    "                tmp_lable = str(root).split(\"/\")[-1]\n",
    "                tmp_file_dir = []\n",
    "                for file in files:\n",
    "                    for ext in self.ACCEPTED_FORMAT:\n",
    "                        if ext in str(file):\n",
    "                            tmp_file_dir.append(os.path.join(root, file))\n",
    "                        \n",
    "                self.raw_dirs.update({tmp_lable:tmp_file_dir})\n",
    "\n",
    "        for key in self.raw_dirs:\n",
    "            print(f'FOUND: {key} -> {len(self.raw_dirs[key])}')\n",
    "\n",
    "    def audio_preprocessing(self):\n",
    "        print('\\nConvering audio files....')\n",
    "        if not os.path.exists(self.OUTPUT_DIR):\n",
    "            os.makedirs(self.OUTPUT_DIR)\n",
    "\n",
    "        for key, item in self.raw_dirs.items():\n",
    "            print(f'Converting and augmenting {key} data ->> ...')\n",
    "            tmp_dir_key = os.path.join(self.OUTPUT_DIR, key)\n",
    "            if not os.path.exists(tmp_dir_key):\n",
    "                os.makedirs(tmp_dir_key)\n",
    "\n",
    "            tmp_arr_mp3_dir = []\n",
    "            for dir in item:\n",
    "                try:\n",
    "                    # read file\n",
    "                    tmp_file_name = str(dir).split(\"/\")[-1].split('.')[0]\n",
    "                    raw_sound = AudioSegment.from_file(dir, format=dir.split('.')[-1])\n",
    "\n",
    "                    # normalise file\n",
    "                    norm_sound = effects.normalize(raw_sound)\n",
    "\n",
    "                    # trim file\n",
    "                    arr_split_file = [norm_sound[idx:idx + self.CLIP_LENGTH] for idx in range(0, len(norm_sound), self.CLIP_LENGTH)]             \n",
    "                    for count_sample, sample in enumerate(arr_split_file):\n",
    "                        #frequency shift\n",
    "                        octave = -0.5\n",
    "                        new_sample_rate = int(sample.frame_rate * (2.0 ** octave))\n",
    "                        freg_shift_sample = sample._spawn(sample.raw_data, overrides={'frame_rate': new_sample_rate})\n",
    "                        \n",
    "                        # export freq_shift file\n",
    "                        tmp_freq_new_dir = os.path.join(tmp_dir_key, tmp_file_name + '_freq_' + str(count_sample) + '.' + self.TARGET_FORMAT)\n",
    "                        freg_shift_sample.export(tmp_freq_new_dir, format=self.TARGET_FORMAT, bitrate=self.BITRATE)\n",
    "                        tmp_arr_mp3_dir.append(tmp_freq_new_dir)\n",
    "\n",
    "                        # export raw file\n",
    "                        tmp_raw_new_dir = os.path.join(tmp_dir_key, tmp_file_name + '_raw_' + str(count_sample) + '.' + self.TARGET_FORMAT)\n",
    "                        sample.export(tmp_raw_new_dir, format=self.TARGET_FORMAT, bitrate=self.BITRATE)\n",
    "                        tmp_arr_mp3_dir.append(tmp_raw_new_dir)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "            \n",
    "            self.mp3_dirs.update({key: tmp_arr_mp3_dir})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for files... acceptable formats include: ['.mp3', '.flac', '.aiff', '.mp4', '.m4a', '.wav', '.ogg']\n",
      "FOUND: jabwar -> 78\n",
      "FOUND: wiltur -> 76\n",
      "FOUND: sheowl -> 128\n",
      "FOUND: brant -> 135\n",
      "FOUND: spodov -> 107\n",
      "\n",
      "Convering audio files....\n",
      "Converting and augmenting jabwar data ->> ...\n",
      "Converting and augmenting wiltur data ->> ...\n",
      "Converting and augmenting sheowl data ->> ...\n",
      "Converting and augmenting brant data ->> ...\n",
      "Converting and augmenting spodov data ->> ...\n"
     ]
    }
   ],
   "source": [
    "data_preprocessing_pipeline = raw_file_pre_processing()\n",
    "\n",
    "data_preprocessing_pipeline.get_raw_file_paths(DATASET_PATH)\n",
    "data_preprocessing_pipeline.audio_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mel_spectrogram_pipeline():\n",
    "    def __init__(self) -> None:\n",
    "        self.target_dir = ''\n",
    "        self.labels = []\n",
    "        self.augmented_dirs = {}\n",
    "        self.OUTPUT_DIR = os.path.join(DATASET_PATH, 'output')\n",
    "        self.ACCEPTED_FORMAT = '.mp3'\n",
    "        self.TENSOR_OUTPUT_DIR = os.path.join(DATASET_PATH, 'tensors')\n",
    "            \n",
    "    def get_preprocessed_files(self):\n",
    "        print(f'Looking for preprocessed files in output dir')\n",
    "        for root, dir, files in os.walk(self.OUTPUT_DIR):\n",
    "            if dir == [] and \"output\" not in str(root).split(\"/\")[1]:\n",
    "                tmp_lable = str(root).split(\"/\")[-1]\n",
    "                tmp_file_dir = []\n",
    "                for file in files:\n",
    "                    if self.ACCEPTED_FORMAT in str(file):\n",
    "                        tmp_file_dir.append(os.path.join(root, file))\n",
    "                        \n",
    "                self.augmented_dirs.update({tmp_lable:tmp_file_dir})\n",
    "\n",
    "        for key in self.augmented_dirs:\n",
    "            print(f'FOUND: {key} -> {len(self.augmented_dirs[key])}')\n",
    "\n",
    "    def generate_mel_spectrograms(self):\n",
    "        print(f'\\nGenerating melspectrograms... \\n')\n",
    "        for key, item in self.augmented_dirs.items():\n",
    "            for dir in item:\n",
    "                tmp_dir_key = f'{self.TENSOR_OUTPUT_DIR}/{key}/'\n",
    "                if not os.path.exists(tmp_dir_key):\n",
    "                    os.makedirs(tmp_dir_key)\n",
    "\n",
    "                print(dir)\n",
    "                tmp_audio = tfio.audio.AudioIOTensor(dir)\n",
    "                tmp_audio_t = tmp_audio.to_tensor()\n",
    "\n",
    "                # Convert to spectrogram\n",
    "                spectrogram = tfio.audio.spectrogram(\n",
    "                    tmp_audio_t, nfft=512, window=512, stride=256)\n",
    "\n",
    "                # # Convert to mel-spectrogram\n",
    "                mel_spectrogram = tfio.audio.melscale(\n",
    "                    spectrogram, rate=16000, mels=128, fmin=0, fmax=8000)\n",
    "\n",
    "                # Convert to db scale mel-spectrogram\n",
    "                dbscale_mel_spectrogram = tfio.audio.dbscale(\n",
    "                    mel_spectrogram, top_db=80)\n",
    "\n",
    "                # Freq masking\n",
    "                #freq_mask = tfio.audio.freq_mask(dbscale_mel_spectrogram, param=10)\n",
    "\n",
    "                # Time masking\n",
    "                #time_mask = tfio.audio.time_mask(dbscale_mel_spectrogram, param=10)\n",
    "\n",
    "                torch.save(mel_spectrogram, f'{self.TENSOR_OUTPUT_DIR}/{key}/{dir.split(\"/\")[-1].split(\".\")[0]}_mel_spectrogram.pt')\n",
    "                torch.save(dbscale_mel_spectrogram, f'{self.TENSOR_OUTPUT_DIR}/{key}/{dir.split(\"/\")[-1].split(\".\")[0]}_dbscale_mel_spectrogram.pt')\n",
    "                \n",
    "                input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spectro_pipeline = mel_spectrogram_pipeline()\n",
    "\n",
    "data_spectro_pipeline.get_preprocessed_files()\n",
    "data_spectro_pipeline.generate_mel_spectrograms()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
